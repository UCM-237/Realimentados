\chapter{Sistemas lineales}

\section{Mapas lineales}

En este capítulo nos vamos a centrar en una clase de sistema llamado \emph{sistema linea en el espacio de estados}. Primero, necesitamos la noción de que es un \emph{mapa lineal}.

\begin{definition} Considera un mapeado $H: V \to W$. Si $H$ preserva la operación suma y la multiplicación por un escalar, i.e.,
\begin{align}
	H(v_1+v_2) &= H(v_1) + H(v_2), \quad v_1, v_2\in\mathbb{V} \nonumber \\
	H(\alpha v_1) &= \alpha H(v_1), \quad \alpha\in\mathbb{K} \nonumber,
\end{align}
	entonces $H$ es un \emph{mapa lineal}.
\end{definition}

\subsection{Ejercicio: Comprueba si los siguientes mapas son lineales}

\begin{enumerate}
	\item $H_1(v) := Av, A\in\mathbb{R}^{n\times n}, \quad v\in\mathbb{R}^n$
	\item $H_2(v) := \frac{\mathrm{d}}{\mathrm{dt}}(v(t)), \quad v\in\mathcal{C}^1$
	\item $H_3(v) := \int_0^T v(t) dt, \quad v\in\mathcal{C}^1, T\in\mathbb{R}_{\geq 0}$
	\item $H_4(v) := D(v) := v(t - T), \quad v\in\mathcal{C}^1, T\in\mathbb{R}_{\geq 0}$
	\item $H_5(v) := Av + b, \quad A\in\mathbb{R}^{n\times n}, v,b\in\mathbb{R}^n$
\end{enumerate}

\section{Sistemas continuos y lineales en el espacio de estados}

El siguiente sistema define un sistema continuo y lineal en el espacio de estados.

\begin{equation}
	\Sigma := \begin{cases}
	\dot x(t) &= A(t)x(t) + B(t)u(t), \quad x\in\mathbb{R}^n, u\in\mathbb{R}^k \\
	\dot y(t) &= C(t)x(t) + D(t)u(t), \quad y\in\mathbb{R}^m
	\end{cases}
	\label{eq: linsys}
\end{equation}

\subsection{Ejercicio: Escribe un sistema continuo y lineal en el espacio de estados como un diagrama de bloques entrada/salida y comprueba que es un mapa lineal.}

\subsection{Ejercicio: Interconecta sistemas continuos y lineales en el espacio de estados y comprueba que el sistema resultante es otro sistema continuo y lineal en el espacio de estados.}

Reescribe como un único sistema lineal\footnote{Por abreviar, cuando no exista ambiguedad, llamaremos sistema lineal al sistema continuo y lineal en el espacio de estados} como en (\ref{eq: linsys}):

\begin{enumerate}
	\item La conexión en serie (o en cascada) de dos sistemas lineales, i.e., $y_1(t) = u_2(t)$.
	\item La conexión en paralelo de dos sistemas lineales, i.e., $y(t) = y_1(t) + y_2(t)$.
	\item La conexión realimentada, i.e., $u_1(t) = u(t) - y(t)$, asumiendo que $u, y, \in\mathbb{R}^k$.
\end{enumerate}

\begin{figure}
\centering
\begin{tikzpicture}[auto, node distance=3.5cm, >=latex']
	\node [input, name=input] {};
	\node [block, right of=input] (system) {$\Sigma_1$};
	\node [output, right of=system] (output) {};
	\draw [draw,->] (input) -- node {$u(t) = u_1(t)$} (system);
	\draw [->] (system) -- node [name=y] {$y_1(t)$}(output);
	\node [block, right of=output] (system2) {$\Sigma_2$};
	\node [output, right of=system2] (output2) {};
	\draw [draw,->] (output) -- node {$u_2(t)$} (system2);
	\draw [->] (system2) -- node [name=y] {$y_2(t) = y(t)$}(output2);
\end{tikzpicture}
	\caption{Conexión en serie de dos sistemas lineales y continuos en el espacio de estados.}
	\label{fig: series}
\end{figure}

\section{Solución a sistemas continuos lineales en el espacio de estados}
La solución a una ecuación diferencial ordinaria viene dada por la suma de dos soluciones: la solución a la parte homogénea, y la solución a la parte no homogénea.

\begin{equation}
	\dot x(t) = \underbrace{A(t)x(t)}_{\text{homogénea}} + \underbrace{B(t)u(t)}_{\text{no homogénea}}
	\label{eq: xdyn}
\end{equation}

\begin{theorem}{Serie de Peano-Barker.}
La solución única al sistema homogéneo $\dot x = Ax$ viene dada por
	\begin{equation}
		x(t) = \Phi(t,t_0)x(t_0), \quad x(t_0)\in\mathbb{R}^n, t\geq 0,
	\end{equation}
donde
	\begin{align}
		\Phi(t,t_0) := I + \int_{t_0}^t A(s_1)ds_1 + \int_{t_0}^t A(s_1) \int_{t_0}^{s_1} A(s_2)ds_2ds_1 \nonumber \\ + \int_{t_0}^t A(s_1) \int_{t_0}^{s_1} A(s_2)\int_{t_0}^{s_2} A(s_3) ds_3ds_2ds_1 + \dots . \label{eq: ser}
	\end{align}
\end{theorem}
Esbozo de la prueba: \\
Primero calculamos la siguiente derivada
	\begin{align}
		\frac{d}{dt}\Phi(t,t_0) &= A(t) + A(t)\int_{t_0}^{t}A(s_2)ds_2 \nonumber \\ &+ A(t)\int_{t_0}^t A(s_2) \int_{t_0}^{s_2} A(s_3)ds_3ds_2 + \dots \nonumber \\
		&= A(t) \Phi(t,t_0).
	\end{align}
	Afirmamos que la solución a la parte homogénea de (\ref{eq: xdyn}) es $x(t) = \Phi(t,t_0)x_0$ cuya derivada con respecto al tiempo es
\begin{align}
	\frac{d}{dt} x &= \frac{d}{dt}\Phi(t,t_0)x_0 \nonumber \\
	&= A(t) \Phi(t,t_0) x_0 \nonumber \\
	&= A(t)x(t),
\end{align}
lo cual prueba la identidad $\dot x = A(t)x(t)$ dado que $x(t) = \Phi(t,t_0)x_0$. Para terminar la prueba, necesitaríamos probar que la serie (\ref{eq: ser}) converge para todo $t\geq t_0$.

La matriz $\Phi(t,t_0)$ es llamada \textbf{\emph{matriz de transición de estados}}. Dada una condición inicial $x_0$, podemos predecir $x(t)$ en (\ref{eq: xdyn}) iterando $\Phi(t,t_0)$ en el caso de que no existiera ninguna interacción con el sistema, i.e., $u(t) = 0, t\geq t_0$.

\subsection{Ejercicio}
Comprobar que
\begin{align}
	x(t) &= \Phi(t,t_0)x_0 + \int_{t_0}^t \Phi(t,\tau)B(\tau)u(\tau)d\tau  \label{eq: solx} \\
	y(t) &= C(t)\phi(t,t_0)x_0 + \int_{t_0}^t C(t)\Phi(t,\tau)B(\tau)u(\tau)d\tau + D(t)u(t), \label{eq: soly}
\end{align}
son las soluciones a

\begin{align}
	\dot x(t) &= A(t)x(t) + B(t)u(t)  \nonumber \\
	\dot y(t) &= C(t)x(t) + D(t)u(t).  \nonumber
\end{align}

\section{Solución a sistemas invariantes en el tiempo, continuos y lineales en el espacio de estados}

Comunmente conocidos como sistemas \emph{lti} (linear time invariant), son los sistemas en los que nos centraremos principalmente en el resto del curso. La matriz $\Phi(t,t_0)$ puede ser hallada analíticamente cuando $A$ es una matriz de coeficientes constantes. Si $A$ es constante, entonces podemos sacarla de las integrales en (\ref{eq: ser}), quedando
\begin{align}
	\Phi(t,t_0) := I + A \int_{t_0}^t ds_1 + A^2 \int_{t_0}^t \int_{t_0}^{s_1} ds_2ds_1 \nonumber \\ + A^3 \int_{t_0}^t \int_{t_0}^{s_1} \int_{t_0}^{s_2} ds_3ds_2ds_1 + \dots \label{eq: phi},
\end{align}
y observando que las siguientes integrales tienen solución analítica
\begin{align}
	\int_{t_0}^t ds_1 &= (t-t_0) \nonumber \\
	\int_{t_0}^t\int_{t_0}^{s_1} ds_2ds_1 &= \frac{(t-t_0)^2}{2} \nonumber \\
	\vdots \nonumber \\
	\int_{t_0}^t\int_{t_0}^{s_1} \cdots \int_{t_0}^{s_{k-2}}\int_{t_0}^{s_{k-1}}ds_k ds_{k-1} \cdots ds_2ds_1 &= \frac{(t-t_0)^k}{k!}, \nonumber
\end{align}
entonces tenemos que (\ref{eq: phi}) es calculada como
\begin{equation}
	\Phi(t,t_0) = \sum_{k=0}^{\infty} \frac{(t-t_0)^k}{k!}A^k,
\end{equation}
lo cual es familiar a la serie de Taylor de una función exponencial. Por ejemplo, para un escalar $x$, tenemos que $e^x := \sum_{k=0}^{\infty}\frac{1}{k!}x^k = 1 + x + \frac{x^2}{2} + \frac{x^3}{3!} + \dots $. De hecho, la definición de la \emph{exponencial de una matriz} es
\begin{equation}
	exp(A) = I + A + \frac{1}{2} A^2 + \frac{1}{3!} A^3 + \dots
\end{equation}
Fijemos $t_0 = 0$ por conveniencia, entonces
\begin{align}
	\Phi(t,0) &= I + tA + \frac{t^2}{2} A^2 + \frac{t^3}{3!} A^3 + \dots \nonumber \\
	&= exp(At),
\end{align}
por lo tanto, la solución a la parte homogénea (\ref{eq: xdyn}) teniendo $A$ con coeficientes constantes y fijando $t_0 = 0$ es
\begin{equation}
	x(t) = exp(At)x_0,\quad t\geq 0.
	\label{eq: xexp}
\end{equation}

Para continuar, necesitamos el siguiente resultado de álgebra lineal.
\begin{theorem}
\textbf{Forma de Jordan}. Para una matriz cuadrada $A\in\mathbb{C}^{n \times n}$, existe un cambio de base no singular $P\in\mathbb{C}^{n \times n}$ que transforma $A$ en
\begin{equation}
	J = PAP^{-1} = \begin{bmatrix}
		J_1 & 0 & 0 & \dots & 0 \\
		0 & J_2 & 0 & \dots & 0 \\
		0 & 0 & J_3 & \dots & 0 \\
		\vdots & \vdots & \vdots & \cdots & \vdots \\
		0 & 0 & 0 & \cdots & J_l
	\end{bmatrix},
\end{equation}
donde $J_i$ es el bloque de Jordan con forma
	\begin{equation}
	J_i = \begin{bmatrix}
\lambda_i & 1 & 0 & \dots & 0 \\
		0 & \lambda_i & 1 & \dots & 0 \\
		0 & 0 & \lambda_i & \dots & 0 \\
		\vdots & \vdots & \vdots & \cdots & \vdots \\
		0 & 0 & 0 & \cdots & \lambda_i
	\end{bmatrix}_{n_i\times n_i},
	\end{equation}
	en donde cada $\lambda_i$ es un autovalor de $A$, y el número $l$ de bloques de Jordan es igual al número total de autovectores independientes de $A$. La matrix $J$ es única (descontando reordenación de filas/columnas) y es llamada la \textbf{forma normal de Jordan} de $A$.
\end{theorem}

Partiendo de la observación que $A = P^{-1}JP$ también, entonces es fácil probar que 
\begin{equation}
	A^k = P^{-1} J^k P,
\end{equation}
de tal manera que podamos calcular que
\begin{align}
	exp(At) &= P^{-1}\left(\sum_{k=1}^\infty \frac{t^k}{k!} \begin{bmatrix}J_1^k & 0 & \cdots & 0 \\ 0 & J_2^k & \cdots & 0 \\ \vdots & \vdots & \cdots & \vdots \\ 0 & 0 & \cdots & J_l^k \end{bmatrix} \right) P \nonumber \\
		&= P^{-1} \begin{bmatrix}exp(J_1t) & 0 & \cdots & 0 \\ 0 & exp(J_2t) & \cdots & 0 \\ \vdots & \vdots & \cdots & \vdots \\ 0 & 0 & \cdots & exp(J_lt) \end{bmatrix} P
\end{align}

Observa que si $J$ es simplemente una matriz diagonal con los autovalores de $A$, i.e., $J_l = \lambda_l \in \mathbb{C}$, entonces $exp(J_lt) = e^{\lambda_lt} \in\mathbb{C}$ es un cálculo trivial.

Now, let us check the consequencues on the following two conditions
Ahora, veamos las consecuencias de las siguientes dos suposiciones
\begin{enumerate}
	\item $J$ es diagonal.
	\item Todos los autovalores de $A$ tienen parte real negativa.
\end{enumerate}

Sabiendo que $\lim_{t\to\infty} e^{\lambda t} \to 0$ si $\lambda \in \mathbb{R}_{<0}$, entonces tenemos que $exp(At) \to 0$ según $t\to\infty$ si las dos previas suposiciones se dan. Si echamos un vistazo a (\ref{eq: xexp}), podemos concluir que 
\begin{equation}
	\lim_{t\to\infty} x(t) \to 0,
	\label{eq: xlim}
\end{equation}
por tanto, podemos predecir la evolución de $x(t)$ con sólamente mirar los autovalores de $A$. Si $J$ no es diagonal, podremos concluir más resultados. Lo veremos en la sección siguiente a la linearización de sistemas en el espacio de estados.


\section{Linearización de sistemas en el espacio de estados}
Desafortunadamente, es realmente dificil (cuando no imposible) calcular una solución analítica para $x(t)$ e $y(t)$ para un sistema arbitrario $\Sigma$ como en (\ref{eq: sigma}). No obstante, hemos visto que sí se puede calcular una solución analítica para $x(t)$ e $y(t)$ cuando $\Sigma$ es un sistema invariante en el tiempo, continuo y lineal en el espacio de estados.

Será de gran utilidad encontrar una relación entre ambos sistemas.

Si $f(x,t)$ y $g(x,t)$ son reales analíticas en un entorno a un punto específico $(x^*,u^*)$, entonces podemos trabajar con aproximaciones de Taylor de $f(x,t)$ y $g(x,t)$ en ese mismo entorno. Cuando nos quedamos en orden uno en la aproximación es lo que se conoce como \emph{linearización}.
\begin{equation}
	\Sigma := \left.\begin{cases}
	\dot x(t) =& f(x(t),u(t)) \\ y(t) =& g(x(t),u(t))
	\end{cases}\right|_{x\approx x^*, u\approx u^*} \approx
	\begin{cases}
		x(t) &= x^* + \delta x(t) \\
		u(t) &= u^* + \delta u(t) \\
	\delta \dot x(t) &= A(t)\delta x(t) + B(t)\delta u(t) \\
	\delta y(t) &= C(t)\delta x(t) + D(t)\delta u(t)
	\end{cases}, \nonumber
\end{equation}
donde
\begin{align}
	A(t) &= \begin{bmatrix}
		\frac{\partial f_1}{\partial x_1} & \dots & \frac{\partial f_1}{\partial x_n} \\
		\vdots & \vdots & \vdots \\
		\frac{\partial f_n}{\partial x_1} & \dots & \frac{\partial f_n}{\partial x_n}
	\end{bmatrix}_{|_{x=x^*, u=u^*}} \quad
	&B(t) = \begin{bmatrix}
		\frac{\partial f_1}{\partial u_1} & \dots & \frac{\partial f_1}{\partial u_k} \\
		\vdots & \vdots & \vdots \\
		\frac{\partial f_k}{\partial u_1} & \dots & \frac{\partial f_k}{\partial u_k}
	\end{bmatrix}_{|_{x=x^*, u=u^*}} \nonumber \\
	C(t) &= \begin{bmatrix}
		\frac{\partial g_1}{\partial x_1} & \dots & \frac{\partial g_1}{\partial x_n} \\
		\vdots & \vdots & \vdots \\
		\frac{\partial g_m}{\partial x_1} & \dots & \frac{\partial g_m}{\partial x_n}
	\end{bmatrix}_{|_{x=x^*, u=u^*}} \quad
	&D(t) = \begin{bmatrix}
		\frac{\partial g_1}{\partial u_1} & \dots & \frac{\partial g_1}{\partial u_k} \\
		\vdots & \vdots & \vdots \\
		\frac{\partial g_m}{\partial u_1} & \dots & \frac{\partial g_m}{\partial u_k}
	\end{bmatrix}_{|_{x=x^*, u=u^*}}. \nonumber
\end{align}
Informalmente, estamos calculando la sensibilidad (hasta primer orden) de $f$ y $g$ cuando hacemos una variación pequeña de $x$ y $u$ alrededor de $(x^*,u^*)$. Como de pequeña ha de ser esa variación depende del sistema $\Sigma$. En particular, cuando diseñemos controladores basados en linearizar alrededor de un punto, daremos cotas para $\delta x$ y $\delta u$ de tal manera que el controlador pueda garantizar estabilidad.

\subsection{Ejercicio. Linearización del péndulo invertido}
Más adelante, veremos que podemos diseñar una entrada de control $u(t)$, i.e., una señal que ha de seguir el torque $T$ en (\ref{eq: f}) de tal manera que $\theta$ y $\dot\theta$ converjan a unos valores constantes o trayectorias deseadas.

Por ejemplo, vamos a fijar un punto constante de interés $x^* = \begin{bmatrix}\theta^* \\ 0\end{bmatrix}$, por lo que la velocidad angular se marca a cero. Esta situación corresponde a una situación de equilibrio para el ángulo $\theta$. Para hallar el $u^*(t)$ en (\ref{eq: f}) necesario para tal equilibrio necesitamos que $\frac{\mathrm{d}}{\mathrm{dt}}\left(\begin{bmatrix}\theta \\ \dot\theta \end{bmatrix}\right) = \begin{bmatrix}0 \\ 0 \end{bmatrix}$. Una inspección a la dinámica (\ref{eq: dyn}) nos responde que
\begin{equation}
	u^* = T^* = -\frac{g}{l}\sin\theta^*,
\end{equation}
por ejemplo, para una posición totalmente vertical correspondiente a $\theta^* = 0$ tenemos que $T^*=0$, i.e., $x^* = \begin{bmatrix}0\\0\end{bmatrix}$ y $u^* = 0$.

El cáclulo de las matrices $A,B,C,$ y $D$ son los Jacobianos de $(\ref{eq: f})$ y $(\ref{eq: g})$, i.e.,

\begin{align}
\frac{\partial f_1}{\partial x_1} &= 0 \nonumber \\
\frac{\partial f_1}{\partial x_2} &= 1 \nonumber \\
\frac{\partial f_2}{\partial x_1} &= \frac{g}{l}\cos\theta \nonumber \\
\frac{\partial f_2}{\partial x_2} &= -\frac{b}{ml^2} \nonumber \\
\frac{\partial f_1}{\partial u_1} &= 0 \nonumber \\
\frac{\partial f_2}{\partial u_1} &= 1 \nonumber \\
\frac{\partial g_1}{\partial x_1} &= 1 \nonumber \\
\frac{\partial g_1}{\partial x_2} &= 0 \nonumber \\
\frac{\partial g_1}{\partial u_1} &= 0, \nonumber
\end{align}
por lo que podemos llegar a
\begin{align}
	\frac{\mathrm{d}}{\mathrm{dt}}\left(\begin{bmatrix}\delta\theta \\ \dot\delta\theta \end{bmatrix}\right) &= \begin{bmatrix}0 & 1 \\ \frac{g}{l}\cos\theta & -\frac{b}{ml^2} \end{bmatrix}_{|_{\theta=\theta^*}} \begin{bmatrix}\delta\theta \\ \dot\delta\theta \end{bmatrix} + \begin{bmatrix}0 \\ 1 \end{bmatrix} \delta T \nonumber \\
		\delta y &= \begin{bmatrix}1 & 0\end{bmatrix}\begin{bmatrix}\delta\theta \\ \dot\delta\theta \end{bmatrix} + 0 \, \delta T,
\end{align}
para modelar una aproximación a la dinámica de $x(t)$ y la salida $y(t)$ alrededor de los puntos $x^*$ y $u^*$.

\section{(Internal or Lyapunov) Stability}
\label{sec: sta}

Decimos que el sistema lineal (\ref{eq: linsys}) \emph{en el sentido de Lyapunov}
\begin{enumerate}
	\item es \emph{(marginalmente) estable} si para cada condición inicial $x_0$, entonces $x(t) = \Phi(t,t_0) x_0$ está acotada uniformamente para todo $t>t_0$.
	\item es \emph{asintóticamente estable} si admeás $x(t) \to 0$ según $t\to\infty$.
	\item es \emph{exponencialmente estable} si además $||x(t)|| \leq c e^{\lambda(t-t_0)}||x(t_0)||$ para algunas constantes $c,\lambda > 0$.
	\item is \emph{inestable} si no es marginalmente estable.
\end{enumerate}

%In control, it is very common to focus on \emph{error signals}, e.g., $e(t) := x(t) - x^*(t)$, where $x^*(t)$ is a trajectory goal. Note that if $x^*$ is constant, then $\dot e(t) = \dot x(t)$, and this is why we focus on having $x(t) \to 0$ as $t\to\infty$ in the above definitions for (\ref{eq: sigmalin}).

Centrémonos en sistemas \emph{lti}, es decir, cuando $A$ tiene coeficientes constantes o $\Phi(t,t_0) = e^{A(t-t_0)}$. Entonces, podemos establecer una clara relación entre los autovalores de $A$ y las definiciones de estabilidad en el sentido de Lyapunov únicamente inspeccionando la solución a $\dot x(t) = Ax(t)$ dada por (\ref{eq: solx}).

El sistema $\dot x(t) = Ax(t)$
\begin{enumerate}
	\item es marginalmente estable si y solo si todos los autovalores de $A$ tienen parte real negativa. Si algún autovalor tiene parte real nula, entonces su bloque de Jordan ha de ser $1\times 1$.
	\item es asintóticamente estable si y solo si todos los autovales de $A$ tienen estrictamente parte real negativa.
	\item es exponencialmente estable si es asintóticamente estable.
	\item es inestable si y solo si al menos un autovalor de $A$ tiene parte real positiva, o al menos uno de los autovalores con parte real nula tiene un bloque de Jordan mayor de $1\times 1$.
\end{enumerate}

Comprobando las soluciones (\ref{eq: solx})-(\ref{eq: soly}), podemos decir que si $A$ tiene coeficientes constantes y $\dot x = Ax$ es asintóticamente estable, entonces $x(t) \to \int_{t_0}^t e^{A(t-\tau)}B(\tau)u(\tau)d\tau$ según $t\to\infty$. 

\subsection{Estabilidad local de sistemas linearizados}
The following equation is also equivalent to have asymptotic (exponential) stability for $\dot x(t) = Ax(t)$. There exists a unique solution $P$ for the following \emph{Lyapunov equation}
\begin{equation}
A^TP + PA = -Q, \quad \forall Q \succ 0.
	\label{eq: lya}
\end{equation}
You can prove (\ref{eq: lya}) by considering
\begin{equation}
	P:= \int_0^\infty e^{A^Tt}Qe^{At}dt.
	\label{eq: P}
\end{equation}
Hint: First, substitute $P$ in (\ref{eq: lya}), and then check the calculation $\frac{\mathrm{d}}{\mathrm{dt}}\left(e^{A^Tt}Qe^{At}\right)$. Since $P$ is unique, then $P$ must be positive definite according to its definition (\ref{eq: P}).

Let us consider an autonomous continuous-time nonlinear system
\begin{equation}
	\dot x(t) = f(x(t)), \quad x\in\mathbb{R}^n,
	\label{eq: non}
\end{equation}
with an equilibrium point $x^*\in\mathbb{R}^n$, i.e., $f(x^*) = 0$. The dynamics of $x(t)$ around $x^*$ can be approximated by considering $x(t) = x^* + \delta x(t)$ where
\begin{equation}
	\dot{\delta x(t)} = A\,\delta x(t), \quad A:=\frac{\partial f(x)}{\partial x}.
	\label{eq: delta}
\end{equation}

What is this approximation good for?

\begin{theorem}
	\label{thm: tayl}
	Assume that $f(x)$ is twice differentiable. If (\ref{eq: delta}) is exponentially stable, then there exists a neighborhood $\mathcal{B}$ around $x^*$ and constants $c, \lambda > 0$ such that for every solution $x(t)$ to the nonlinear system (\ref{eq: non}) that starts at $x(t_0)\in\mathcal{B}$, we have
	\begin{equation}
	||x(t) - x^*|| \leq ce^{\lambda(t-t_0)} ||x(t_0) - x^*||, \quad \forall t\geq t_0.
	\end{equation}
\end{theorem}

\subsubsection{How big is $\mathcal{B}$? Can we estimate it? Sketch of the proof of Theorem \ref{thm: tayl}}

Since $f$ is twice differentiable, from its Taylor's series we have that
\begin{equation}
	r(x) := f(x) - (f(x^*) + A(x - x^*)) = f(x) - A\,\delta x = O(||\delta x||^2),
\end{equation}
which means that there exist a constant $c$ and a ball $\bar B$ around $x^*$ such that
\begin{equation}
	||r(x)|| \leq c||\delta x||^2, \quad x\in\bar B.
\end{equation}
If the linearized system is exponentially stable, we have that
\begin{equation}
A^TP + PA = -I.
\end{equation}
Now consider the following scalar signal
\begin{equation}
	v(t) := (\delta x)^T P \delta x, \quad \forall t\geq 0.
\end{equation}
Noting that $\delta x(t) = x(t) - x^*$, then $\dot{\delta x(t)} = \dot x(t) = f(t)$. Therefore, the time derivative of $v(t)$ satisfies
\begin{align}
	\dot v &= f(x)^T P \delta x + (\delta x)^T P f(x) \nonumber \\
	&= (A\delta x + r(x))^T P \delta x + (\delta x)^T P (A\delta x + r(x)) \nonumber \\
	&= (\delta x)^T(A^T P + PA)\delta x + 2(\delta x)^T P r(x) \nonumber \\
	&= -||\delta x||^2 + 2(\delta x)^T P r(x) \nonumber \\
	&\leq -||\delta x||^2 + 2 ||P||\, ||\delta x|| \, ||r(x)||.
\end{align}

We have that $v(t)$ is positive excepting when $\delta x = 0$. If we can guarantee that $\dot v(t) < 0$ and $\dot v(t) = 0$ only when $\delta x = 0$, then $v(t) \to 0$ as $t\to\infty$, which means that $\delta x(t) \to 0$ as $t\to\infty$.

Now, if $x\in\mathcal{\bar B}$, then
\begin{equation}
	\dot v \leq -\Big(1 - 2c\,||P||\,||\delta x||\Big)||\delta x||^2,
\end{equation}
Thus, if the deviation $\delta x$ is small enough, i.e.,
\begin{equation}
||\delta x|| < \frac{1}{2c||P||},
\end{equation}
then $\dot v(t) < 0$ if $\delta x(0) \neq 0$ and $\delta x(0) < \frac{1}{2c||P||}$.

We can conclude that an estimation of $\mathcal B$ is
\begin{equation}
	\mathcal{B} := \{ \delta x : ||\delta x|| < \frac{1}{2c||P||} \}.
	\label{eq: Bregion}
\end{equation}

\section{Controllability}
\subsection{Reachable and Controllable subspaces}
We recall that when we apply an input $u(\cdot)$ to (\ref{eq: sigmalin}), we transfer the system from a state $x(t_0):=x_0$ to a state $x(t_1):=x_1$, and it is calculated from (\ref{eq: solx}) as follows
\begin{equation}
	x_1 = \Phi(t_1,t_0)x_0 + \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)u(\tau)d\tau,
\end{equation}
where $\Phi(\cdot)$ is the system's state transition matrix.

Questions: 
\begin{enumerate}
	\item Which states can I reach from $x_0$?
	\item Is there always an input $u(\cdot)$ that transfers the system from an arbirtrary state $x_0$ to another arbitrary state $x_1$?
\end{enumerate}

These two questions lead to the definition of the reachable and controllable subspaces.

\begin{definition}[Reachable subspace]
	Given two times $t_1>t_0\geq 0$, the reachable or controllable-from-the-origin on $[t_0,t_1]$ subspace $\mathcal{R}[t_0,t_1]$ consists of all the states $x_1$ for wichi there exists an input $u:[t_0,t_1]\to \mathbb{R}^k$ that transfers the state from $x_0 = 0$ to $x_1 \in\mathbb{R}^n$; i.e.,
	\begin{equation}
		\mathcal{R}[t_0,t_1] := \Big\{x_1\in\mathbb{R}^n : \exists u(\cdot),\, x_1 = \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)u(\tau)d\tau \Big\}. \label{eq: rs}
	\end{equation}
\end{definition}

\begin{definition}[Controllable subspace]
	Given two times $t_1>t_0\geq 0$, the controllable or controllable-to-the-origin on $[t_0,t_1]$ subspace $\mathcal{C}[t_0,t_1]$ consists of all the states $x_1$ for wichi there exists an input $u:[t_0,t_1]\to \mathbb{R}^k$ that transfers the state from $x_0\in\mathbb{R}^n$ to $x_1 = 0$; i.e.,
	\begin{equation}
		\mathcal{C}[t_0,t_1] := \Big\{x_0\in\mathbb{R}^n : \exists u(\cdot),\, 0 = \Phi(t_1,t_0)x_0 + \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)u(\tau)d\tau \Big\}.
	\end{equation}
\end{definition}

How to calculate the $\mathcal{R}[t_0,t_1]$ and $\mathcal{C}[t_0,t_1]$ subspaces? We will exploit the following two matrices called \emph{Gramians}.

\begin{definition}[Reachability and Controllability Gramians]
	\begin{align}
		W_R(t_0,t_1) &:= \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)B(\tau)^T\Phi(t_1,\tau)^Td\tau \\
		W_C(t_0,t_1) &:= \int_{t_0}^{t_1} \Phi(t_0,\tau)B(\tau)B(\tau)^T\Phi(t_0,\tau)^Td\tau 
	\end{align}
\end{definition}

\begin{theorem}
Given two times $t_1 > t_0 \geq 0$,
	\begin{align}
		\mathcal{R}[t_0,t_1] &= \text{Im}\{W_R(t_0,t_1)\} \label{RI} \\
		\mathcal{C}[t_0,t_1] &= \text{Im}\{W_C(t_0,t_1)\} \label{CI},
	\end{align}
	where $\text{Im}\{A\}:= \Big\{y\in\mathbb{R}^m: \exists x\in\mathbb{R}^n, y = Ax\Big\}$ for a matrix $A\in\mathbb{R}^{m\times n}$.
\end{theorem}
\begin{proof}
	We will only prove (\ref{RI}) since (\ref{CI}) has a similar proof.
	We need to show both ways: firsty, if $x_1 \in \text{Im}\{W_R(t_0,t_1)$, then $x_1 \in \mathcal{R}[t_0,t_1]$; secondly, if $x_1 \in \mathcal{R}[t_0,t_1]$ then $x_1 \in \text{Im}\{W_R(t_0,t_1)$.\\
	When $x_1 \in \text{Im}\{W_R(t_0,t_1)$, there exists a vector $\mu_1\in\mathbb{R}^n$ such that
	\begin{equation}
	x_1 = W_R(t_0,t_1)\eta_1.
	\end{equation}
	Choose $u(\tau) = B(\tau)^T\Phi(t_1, \tau)^T\eta_1$, and plug it into (\ref{eq: rs}), then we have that
	\begin{equation}
	x_1 = \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau) B(\tau)^T\Phi(t_1, \tau)^T \eta_1d\tau = W_R(t_0,t_1)\eta_1.
	\end{equation}
	When $x_1 \in \mathcal{R}[t_0,t_1]$, there exists an input $u(\cdot)$ for which
	\begin{equation}
		x_1 = \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)u(\tau)d\tau.
		\label{x1}
	\end{equation}
	If (\ref{x1}) is in $\text{Im}\{W_R(t_0,t_1)\}$, then $x_1^T\mu = 0, \, \mu \in \text{Ker}\{W_R(t_0,t_1)\}$\footnote{If $x\in\text{Ker}\{A^T\}$, then $A^Tx = 0$. If $y\in\text{Im}\{A\}$, then $y = A\eta$. Thus, $x^Ty = x^TA\eta = \eta^TA^Tx = \eta \cdot 0 = 0$. Note that $W_R^T = W_R$ by definition.}. Let us calculate
	\begin{equation}
		x_1^T\mu = \int_{t_0}^{t_1}u(\tau)^TB(\tau)^T\Phi(t_1,\tau)^T\mu \, d\tau. \label{eq: x1eta1}
	\end{equation}
	And noting that
	\begin{align}
	\mu \in \text{Ker}\{W_R(t_0,t_1)\} \implies \mu^TW_R(t_0,t_1)\mu &= 0 \nonumber \\ &= \int_{t_0}^{t_1}\mu^T \Phi(t_1,\tau)B(\tau)B(\tau)^T\Phi(t_1,\tau)^T \mu \, d\tau \nonumber \\ &= \int_{t_0}^{t_1} ||B(\tau)^T\Phi(t_1,\tau)^T \mu||^2 d \tau,
	\end{align}
	give us that $B(\tau)^T\Phi(t_1,\tau)^T \mu  = 0$, leading to (\ref{eq: x1eta1}) equals zero.
\end{proof}
\begin{remark}
Note that we have proven that $u(\tau) = B(\tau)^T\Phi(t_1,\tau)^T \eta_1$ can be used as a control input to transfer the system from $x_0 = 0$ to $x_1\in\mathbb{R}^n$ in the finite time $(t_1 - t_0)$. In fact, this is the \emph{open-loop minimun energy control}.
\end{remark}
To see this fact, consider another control input $\bar u(t)$ so that
\begin{equation}
x_1 = \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)u(\tau)d\tau = \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)\bar u(\tau)d\tau.
\end{equation}
For this to hold, we must have
\begin{equation}
	\int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)v(\tau) \, d\tau = 0,
	\label{eq: ve}
\end{equation}
where $v(\tau) = u(\tau) - \bar u(\tau)$.
Let us see the energy of $\bar u$
\begin{align}
\int_{t_0}^{t_1}||\bar u(\tau)||^2 d\tau &= \int_{t_0}^{t_1} || B(\tau)^T\Phi(t_1,\tau)^T \eta_1 + v(\tau)||^2 d\tau \nonumber \\ 
&= \eta_1^T W_R(t_0,t_1)\eta_1 + \int_{t_0}^{t_1} ||v(\tau)||^2 d \tau + 2\eta_1^T \int_{t_0}^{t_1}B(\tau)\Phi(t_1,\tau)v(\tau) d \tau
\end{align}
where the third term is zero because of (\ref{eq: ve}). Hence, if $\bar u(t)$ difers $v(t)$ from $u(t)$, it will expend $\int_{t_0}^{t_1} ||v(\tau)||^2 d\tau$ more energy than $u(t)$.

\subsection{Controllability matrix for $A,B$ being constant}

We have that the Cayley-Hamilton theorem allows us to write
\begin{equation}
	e^{At} = \sum_{i=0}^{n-1}\alpha_i(t)A^i, \quad \forall t\in\mathbb{R},
\end{equation}
for some appropriate scalar functions $\alpha_i(t)$. We also have that if $A$ and $B$ are constant then
\begin{align}
	x_1 &= \int_{0}^{t_0-t_1} e^{At}Bu(t) dt \nonumber \\
	&= \sum_{i=0}^{n-1} A^iB \Big(\int_{0}^{t_1-t_0}\alpha_i(t)u(t)dt \Big) \nonumber \\
	&= \mathcal{C} \begin{bmatrix}\int_{0}^{t_1-t_0}\alpha_0(t)u(t)dt \\ \vdots \\ \int_{0}^{t_1-t_0} \alpha_{n-1}(t)u(t)dt \end{bmatrix},
\end{align}
where $\mathcal{C}:=\begin{bmatrix}B & AB & A^2B & \cdots & A^{n-1}B
\end{bmatrix}_{n\times (kn)}$\footnote{Please, note that $\mathcal{C}[t_0,t_1]$ and $\mathcal{C}$ are different objects. The former is a space, the latter is a matrix.}.
Note that we just have proven that the image of $\mathcal{C}$ is the same as the image of $W_R(t_0,t_1)$. The following more general result can be proven as well:

\begin{theorem}
	\label{thm: spcon}
For any two times $t_0, t_1$, with $t_1 > t_0$, we have
	\begin{equation}
		\mathcal{R}[t_0,t_1] = \text{Im}\{W_R(t_0,t_1)\} = \text{Im}\{\mathcal{C}\} = \text{Im}\{W_C(t_0,t_1)\} = \mathcal{C}[t_0,t_1],
	\end{equation}
\end{theorem}

Two important consequences can be extracted from Theorem \ref{thm: spcon} for systems with $A$ and $B$ constant. Note that $\text{Im}\{\mathcal{C}\}$ does not depend on any time variable!
\begin{enumerate}
	\item \emph{Time reversibility}: If you can reach $x_1$ from zero, then you can reach zero from $x_1$, i.e, the controllability and reachibility subspaces are the same.
	\item \emph{Time scaling}: The notions of reachable and controllable subspaces do not depend on the considered time interval. If you can transfer the state from $x_0$ to $x_1$ in $t$ seconds, then you can also do it in $\bar t$ seconds.
\end{enumerate}

\begin{definition}
	Given two times $t_1 > t_0 \geq 0$, the pair $(A,B)$ from system (\ref{eq: sigmalin}) is reachable on $[t_0, t_1]$ if $\mathcal{R}[t_0,t_1] = \mathbb{R}^n$, i.e., if we can drive the state of the system from the origin to any arbitrary state in finite time.
\end{definition}

\begin{definition}
	\label{def: con}
	Given two times $t_1 > t_0 \geq 0$, the pair $(A,B)$ from system (\ref{eq: sigmalin}) is controllable on $[t_0, t_1]$ if $\mathcal{C}[t_0,t_1] = \mathbb{R}^n$, i.e., if every state can be driven to the origin in finite time.
\end{definition}

\subsection{Controllability tests}
The following theorem is the combination of the Definition \ref{def: con} and Theorem \ref{thm: spcon}:
\begin{theorem}
	The (constant) pair $(A,B)$ is controllable if and only if the rank of $\mathcal{C}$ is $n$.
\end{theorem}

The following theorem is an easy check numerically.
\begin{theorem}
	\label{thm: atbt}
	The (constant) pair $(A,B)$ is controllable if and only if there is no eigenvector of $A^T$ in the kernel of $B^T$.
\end{theorem}
The following theorem is a restatement of the previous one.
\begin{theorem}
	The (constant) pair $(A,B)$ is controllable if and only if the rank of $\begin{bmatrix}A-\lambda I & B\end{bmatrix}$ is $n$.
\end{theorem}

\begin{remark}
	Note that having an asymptotically stable system does not imply to have a controllable system (pair (A,B) controllable). Let us also illustrate Theorem \ref{thm: atbt} with the following system:
\begin{equation}
	\dot x = \begin{bmatrix}-3 & 0 \\ 0 & -7\end{bmatrix}x + \begin{bmatrix}0 \\ 1\end{bmatrix}u, \quad x\in\mathbb{R}^2, u\in\mathbb{R}.
\end{equation}
	The kernel of $B^T$ is spanned by $\begin{bmatrix}1 \\ 0\end{bmatrix}$, which is an eigenvector of $A = A^T$. Therefore, the system is not controllable according to Theorem \ref{thm: atbt}. Note that we do not have any control over $x_1$ via $u$. However, it is asympotically stable. One can see that $x_{\{1,2\}}(t) \to 0$ as $t\to\infty$ when $u = 0$. Remember that controllability is about going from a nonzero state $x^*$ to $0$ in \textbf{finite time}.
\end{remark}

\section{Feedback stabilization based on the Lyapunov test}
\subsection{Lyapunov test for stabilization}
\begin{definition}
The system (\ref{eq: sigmalin}) is stabilizable if there exists an input $u(t)$ for every $x(0)$ such that $x(t)\to 0$ as $t\to\infty$.
\end{definition}
This is somehow a \emph{controllable} version of the system in infinite time instead of in finite time. In the next theorem, we will see that \emph{stabilizable} is less restrictive than \emph{controllable}.

\begin{theorem}
The system (\ref{eq: sigmalin}) is stabilizable if and only if every eigen-vector of $A^T$ corresponding to an eigenvalue with a positive or zero real part is not in the kernel of $B^T$.
\end{theorem}

The components of $x(t)$ corresponding to the eigenvectors with associated eigenvalues with negative real part go to zero as the time goes to infinity without any \emph{assistance} from an input. Therefore, the input $u(t)$ must counterreact the components corresponding to the eigenvectors with associated eigenvalues with non-negative real part. For example:
\begin{equation}
	\dot x = \begin{bmatrix}-3 & 0 \\ 0 & 7\end{bmatrix}x + \begin{bmatrix}0 \\ 1\end{bmatrix}u, \quad x\in\mathbb{R}^2, u\in\mathbb{R},
\end{equation}
while we do not have any \emph{authority} over $x_1(t)$, we can employ $u(t)$ to drive $x_2(t)$ to zero so that $x(t)\to 0$ as $t\to\infty$.
\begin{theorem}
	The system (\ref{eq: sigmalin}) is stabilizable if and only if there is a positive-definite solution $P$ to the following Lyapunov matrix inequality
	\begin{equation}
	AP + PA^T - BB^T \prec 0
		\label{eq: lb}
	\end{equation}
\end{theorem}
\begin{proof}
	We will see only one direction of the proof. Do not confuse (\ref{eq: lb}) with the Lyapunov equation\footnote{Note the order of the transposed matrices, and also note the opposite sign of $-BB^T$ and $+I$ for the two equations.} $PA+A^TP \prec -I$ in (\ref{eq: lya}).


Consider $x$ being an eigenvector associated to an eigenvalue $\lambda$ with non-negative real part of $A^T$. Then
	\begin{equation}
	x^*(AP+PA^T)x < x^*BB^Tx = ||B^Tx||^2,
		\label{eq: aux}
	\end{equation}
	where $x^*$ is the complex conjugate transpose of $x$. But the left-hand side of (\ref{eq: aux}) equals
	\begin{equation}
		(A^T(x^*)^T)^TPx + x^*PA^Tx = \lambda^*x^*Px + \lambda x^*Px = 2\text{Real}\{\lambda\}x^*Px.
	\end{equation}
	Since $P$ is positive-definite and $\text{Real}\{\lambda\} \geq 0$, we can conclude that
\begin{equation}
0 \leq 2\text{Real}\{\lambda\}x^*Px < ||B^Tx||^2,
\end{equation}
and therefore $x$ must not belong to the kernel of $B$, otherwise we will have
\begin{equation}
0 \leq 2\text{Real}\{\lambda\}x^*Px < 0,
\end{equation}
which cannot be possible.
\end{proof}

\subsection{State-feedback controller}
Define the \emph{control matrix gain}
\begin{equation}
	K:=\frac{1}{2}B^TP^{-1}, \label{eq: K}
\end{equation}
where $P$ is calculated from (\ref{eq: lb}) if and only if the system (\ref{eq: sigmalin}) is stabilizable. Therefore, we can rewrite (\ref{eq: lb}) as
\begin{equation}
	(A - \frac{1}{2}BB^TP^{-1})P + P(A - \frac{1}{2}BB^TP^{-1})^T = (A-BK)P+P(A-BK)^T \prec 0,
\end{equation}
and by multiplying on the left and right by $Q:=P^{-1}$ we have that
\begin{equation}
	Q(A-BK)+(A-BK)^TQ \prec 0,
\end{equation}
which is the Lyapunov equation. Thus, we can conclude that $(A-BK)$ has all its eigenvalues with negative real part, i.e., if one chooses the input 
\begin{equation}
	u = -Kx = -\frac{1}{2}B^TP^{-1}x, \label{eq: conK}
\end{equation}
in the stabilizable (\ref{eq: sigmalin}), then $x(t) \to 0$ as $t\to\infty$ exponentially fast.

\section{Observability for linear time invariant (lti) systems}
In this section we will consider only the following linear system
\begin{equation}
	\Sigma_{\text{lti}} := \begin{cases}
	\dot x(t) &= Ax(t) + Bu(t) \\
		y(t) &= Cx(t) + Du(t)
	\end{cases}.
\label{eq: sigmalinc}
\end{equation}
\subsection{Unobservable subspace and the observability Gramian}
\begin{definition}
	The \emph{unobservable} subspace $\mathcal{UO}$ of system (\ref{eq: sigmalinc}) consists of all the states $x_0\in\mathbb{R}^n$ such that
	\begin{equation}
	C e^{A} x_0 = 0.
		\label{eq: ce}
	\end{equation}
\end{definition}
This definition is motivated by the following facts.
Recall that from (\ref{eq: soly}) we have that
\begin{align}
	y(t) &= Ce^{At}x_0 + \int_0^tCe^{A(t-\tau)}Bu(\tau)d\tau + Du(t) \nonumber \\
	\tilde y(t) &:= y(t) - \int_0^tCe^{A(t-\tau)}Bu(\tau)d\tau - Du(t) = Ce^{At}x_0. \label{eq: y}
\end{align}
On the left hand side of (\ref{eq: y}) we have a pair input/output, and on the right hand side of (\ref{eq: y}) we have the initial state $x_0$. From (\ref{eq: y}) we can observe two interesting properties:
\begin{enumerate}
	\item When a particular $x_0$ is compatible with an input/output pair, then every initial state of the form $x_0 + x_u, \, x_u\in\mathcal{UO}$, is also compatible with the same input/output pair.
	\item When $\mathcal{UO}$ contains only the zero vector, then there exists at most one initial state $x_0$ that is compatible with the input/output pair.
\end{enumerate}

\begin{definition}
	The system (\ref{eq: sigmalinc}) is observable if its $\mathcal{UO}$ contains only the zero vector.
\end{definition}

\begin{definition}
	Given two times $t_1>t_0\geq 0$, the observability Gramian is defined by
	\begin{equation}
		W_O(t_0,t_1) := \int_{t_0}^{t_1}e^{A^T(\tau - t_0)} C^T Ce^{A(\tau - t_0)}d\tau
	\end{equation}
\end{definition}
There is difference w.r.t. the controllability Gramian, the transposes appear on the left for the observability Gramian, whereas the transposes appear on the right for the controllability Gramian.
Starting with (\ref{eq: ce}), it can be shown that
\begin{equation}
	\operatorname{Ker}W_O(t_0,t_1) = \mathcal{UO}.
\end{equation}

\subsection{Observability tests}
The following can be proven formally by applying the theorem of Cayley-Hamilton\footnote{To see why we stop at $(n-1)$.}. Let us now check the sensibility of $y$ and its time derivatives with respect to $x$ when\footnote{Note that $B$ and $D$ do not play any role for the observability, only $A$ and $C$.} $u(t)=0$
\begin{align}
	y(t) = Cx(t) &\implies \dot y(t) = C\dot x(t) = CAx(t) \implies \ddot y(t) = C A^2 x(t) \quad \dots \nonumber \\ &\implies \frac{\mathrm{d}^{n-1}y}{\mathrm{dt}^{n-1}} = CA^{n-1}x(t), \nonumber
\end{align}
If we do not want to loose any information of the signal $x(t)$, then the matrix
\begin{equation}
	\mathcal{O} = \begin{bmatrix}C \\ CA \\ \vdots \\ CA^{n-1}\end{bmatrix}_{(kn)\times n}, \label{eq: O}
\end{equation}
must be full column rank. We, then, introduce the following equivalent results.
\begin{theorem}
	The system (\ref{eq: sigmalinc}) is observable if and only if the rank of $\mathcal{O}$ equals $n$.
\end{theorem}
\begin{theorem}
The system (\ref{eq: sigmalinc}) is observable if and only if no eigenvector of $A$ is in the kernel of $C$.
\end{theorem}

Note that from (\ref{eq: O}) we can derive a \emph{controllability} test
\begin{equation}
	\mathcal{O}^T = \begin{bmatrix}C^T & A^TC^T & \cdots & (A^{n-1})^TC^T \end{bmatrix}_{n \times (kn)}, 
\end{equation}
from which we can derive from the following \emph{dual} system constructed from (\ref{eq: sigmalinc})
\begin{equation}
	\Sigma_{\text{dual}} := \begin{cases}
		\dot{\bar x}(t) &= A^T \bar x(t) + C^T \bar u(t) \\
		\bar y(t) &= B^T\bar x(t) + D^T\bar u(t)
	\end{cases},
\label{eq: sigmadual}
\end{equation}
then, we have the following result
\begin{theorem}
	The system (\ref{eq: sigmalinc}) is controllable if and only if (\ref{eq: sigmadual}) is observable.
\end{theorem}
Therefore, we only need to study the controllability of the dual system (\ref{eq: sigmalinc}) to conclude about its observability.

\section{State estimation for linear time invariant systems}
The simplest estimator consists of a copy of the system (\ref{eq: sigmalinc})
\begin{equation}
	\Sigma_{\text{estimator}} := \begin{cases}
		\dot{\hat x}(t) &= A \hat x(t) + B u(t) \\
		\hat y(t) &= C\hat x(t) + D u(t)
	\end{cases},
\label{eq: sigmaest}
\end{equation}
and let us define the error signal $e(t) := \hat x(t) - x(t)$. Now, let us check the dynamics of the error signal
\begin{equation}
	\dot e(t) = \dot{\hat x}(t) - \dot x(t) = A\hat x + Bu - Ax - Bu = Ae(t),
\end{equation}
therefore $e(t)\to 0$ as $t\to\infty$ exponentially fast if $A$ is a stability matrix for every input signal $u(t)$.

What if $A$ is not a stability matrix? Then, consider the following system
\begin{equation}
	\Sigma_{\text{estimator2}} := \begin{cases}
		\dot{\hat x}(t) &= A \hat x(t) + B u(t) - L(\hat y(t) - y(t)) \\
		\hat y(t) &= C\hat x(t) + D u(t)
	\end{cases},
\label{eq: sigmaest2}
\end{equation}
where we have \emph{two inputs} $u$ and $(\hat y - y)$, and $L\in\mathbb{R}^{n\times m}$ is a matrix gain. Note that the signal $y$ comes from (\ref{eq: sigmalinc}). Now, let us see the dynamics of the error signal
\begin{equation}
	\dot e = A\hat x + Bu - L(\hat y - y) - (Ax + Bu) = (A-LC)e,\label{eq: ed} 
\end{equation}
thus, if we can make $(A-LC)$ a stability matrix, then $e(t)\to 0$ as $t\to\infty$ exponentially fast for every input signal $u(t)$. 

Sometimes, it is not possible to find such a $L$ because of the structure of $C$ (something similar happened for $K$ and $B$ for the stabilizability and controllability of (\ref{eq: sigmalin})). Then we have a similar result about \emph{detectatbility}.
\begin{theorem}
	The system (\ref{eq: sigmalinc}) is \emph{detectable} if and only if every eigenvector of $A$ corresponding to a non stable eigenvalue is not in the kernel of $C$.
\end{theorem}
Remember, a system is detectable if its dual is stabilizable.
\begin{theorem}
	When a pair $(A,C)$ is detectable, it is always possible to find $L$ such that $(A-LC)$ is a stability matrix.
\end{theorem}
\begin{theorem}
	When a pair $(A,C)$ is observable, it is always possible to find $L$ such that $(A-LC)$ is a stability matrix with an arbitrary set of stable eigenvalues.
\end{theorem}
In such a case, we can always compute $L$ as we have computed $K$ as in (\ref{eq: K}) for controllable systems by analyzing the dual system of (\ref{eq: sigmalinc}). Note that in such a computation, since we are dealing with the dual system, the matrix gain $K$ will be $L^T$.

\section{Stabilization of linear time invariant systems through output feedback}
If $C$ is not invertible, then we do not have \emph{direct access} to the states $x$ in (\ref{eq: sigmalinc}); therefore we cannot apply the control input $u = -Kx$ as in (\ref{eq: conK}).

What if (\ref{eq: sigmalinc}) is observable, or at least detectable? Then, we are going to show that we can employ
\begin{equation}
	u = -K \hat x, \label{eq: uh}
\end{equation}
where $\hat x$ are the states of our estimator (\ref{eq: sigmaest2}), as a control action to stabilize (\ref{eq: sigmalinc}) around the origin. Let us apply (\ref{eq: uh}) in (\ref{eq: sigmalinc}), therefore we have that
\begin{equation}
	\dot x = Ax - BK\hat x = Ax - BK(e + x) = (A -BK)x -BKe,
\end{equation}
that together with (\ref{eq: ed}) give us the following autonomous system
\begin{equation}
	\begin{bmatrix}\dot x \\ \dot e\end{bmatrix} = \begin{bmatrix}A-BK & -BK \\ 0 & A-LC\end{bmatrix}\begin{bmatrix}x \\ e\end{bmatrix},
\end{equation}
which is exponentially stable since $(A-BK)$ and $(A-LC)$ are stability matrices (if our system (\ref{eq: sigmalinc}) is at least stabilizable and detectable) and the triangular structure of the state-transition matrix.

