\chapter{Sistemas lineales}

\section{Mapas lineales}

En este capítulo nos vamos a centrar en una clase de sistema llamado \emph{sistema linea en el espacio de estados}. Primero, necesitamos la noción de que es un \emph{mapa lineal}.

\begin{definition} Considera un mapeado $H: V \to W$. Si $H$ preserva la operación suma y la multiplicación por un escalar, i.e.,
\begin{align}
	H(v_1+v_2) &= H(v_1) + H(v_2), \quad v_1, v_2\in\mathbb{V} \nonumber \\
	H(\alpha v_1) &= \alpha H(v_1), \quad \alpha\in\mathbb{K} \nonumber,
\end{align}
	entonces $H$ es un \emph{mapa lineal}.
\end{definition}

\subsection{Ejercicio: Comprueba si los siguientes mapas son lineales}

\begin{enumerate}
	\item $H_1(v) := Av, A\in\mathbb{R}^{n\times n}, \quad v\in\mathbb{R}^n$
	\item $H_2(v) := \frac{\mathrm{d}}{\mathrm{dt}}(v(t)), \quad v\in\mathcal{C}^1$
	\item $H_3(v) := \int_0^T v(t) dt, \quad v\in\mathcal{C}^1, T\in\mathbb{R}_{\geq 0}$
	\item $H_4(v) := D(v) := v(t - T), \quad v\in\mathcal{C}^1, T\in\mathbb{R}_{\geq 0}$
	\item $H_5(v) := Av + b, \quad A\in\mathbb{R}^{n\times n}, v,b\in\mathbb{R}^n$
\end{enumerate}

\section{Sistemas continuos y lineales en el espacio de estados}

El siguiente sistema define un sistema continuo y lineal en el espacio de estados.

\begin{equation}
	\Sigma := \begin{cases}
	\dot x(t) &= A(t)x(t) + B(t)u(t), \quad x\in\mathbb{R}^n, u\in\mathbb{R}^k \\
	\dot y(t) &= C(t)x(t) + D(t)u(t), \quad y\in\mathbb{R}^m
	\end{cases}
	\label{eq: linsys}
\end{equation}

\subsection{Ejercicio: Escribe un sistema continuo y lineal en el espacio de estados como un diagrama de bloques entrada/salida y comprueba que es un mapa lineal.}

\subsection{Ejercicio: Interconecta sistemas continuos y lineales en el espacio de estados y comprueba que el sistema resultante es otro sistema continuo y lineal en el espacio de estados.}

Reescribe como un único sistema lineal\footnote{Por abreviar, cuando no exista ambiguedad, llamaremos sistema lineal al sistema continuo y lineal en el espacio de estados} como en (\ref{eq: linsys}):

\begin{enumerate}
	\item La conexión en serie (o en cascada) de dos sistemas lineales, i.e., $y_1(t) = u_2(t)$.
	\item La conexión en paralelo de dos sistemas lineales, i.e., $y(t) = y_1(t) + y_2(t)$.
	\item La conexión realimentada, i.e., $u_1(t) = u(t) - y(t)$, asumiendo que $u, y, \in\mathbb{R}^k$.
\end{enumerate}

\begin{figure}
\centering
\begin{tikzpicture}[auto, node distance=3.5cm, >=latex']
	\node [input, name=input] {};
	\node [block, right of=input] (system) {$\Sigma_1$};
	\node [output, right of=system] (output) {};
	\draw [draw,->] (input) -- node {$u(t) = u_1(t)$} (system);
	\draw [->] (system) -- node [name=y] {$y_1(t)$}(output);
	\node [block, right of=output] (system2) {$\Sigma_2$};
	\node [output, right of=system2] (output2) {};
	\draw [draw,->] (output) -- node {$u_2(t)$} (system2);
	\draw [->] (system2) -- node [name=y] {$y_2(t) = y(t)$}(output2);
\end{tikzpicture}
	\caption{Conexión en serie de dos sistemas lineales y continuos en el espacio de estados.}
	\label{fig: series}
\end{figure}

\section{Solución a sistemas continuos lineales en el espacio de estados}
La solución a una ecuación diferencial ordinaria viene dada por la suma de dos soluciones: la solución a la parte homogénea, y la solución a la parte no homogénea.

\begin{equation}
	\dot x(t) = \underbrace{A(t)x(t)}_{\text{homogénea}} + \underbrace{B(t)u(t)}_{\text{no homogénea}}
	\label{eq: xdyn}
\end{equation}

\begin{theorem}{Serie de Peano-Barker.}
La solución única al sistema homogéneo $\dot x = Ax$ viene dada por
	\begin{equation}
		x(t) = \Phi(t,t_0)x(t_0), \quad x(t_0)\in\mathbb{R}^n, t\geq 0,
	\end{equation}
donde
	\begin{align}
		\Phi(t,t_0) := I + \int_{t_0}^t A(s_1)ds_1 + \int_{t_0}^t A(s_1) \int_{t_0}^{s_1} A(s_2)ds_2ds_1 \nonumber \\ + \int_{t_0}^t A(s_1) \int_{t_0}^{s_1} A(s_2)\int_{t_0}^{s_2} A(s_3) ds_3ds_2ds_1 + \dots . \label{eq: ser}
	\end{align}
\end{theorem}
Esbozo de la prueba: \\
Primero calculamos la siguiente derivada
	\begin{align}
		\frac{d}{dt}\Phi(t,t_0) &= A(t) + A(t)\int_{t_0}^{t}A(s_2)ds_2 \nonumber \\ &+ A(t)\int_{t_0}^t A(s_2) \int_{t_0}^{s_2} A(s_3)ds_3ds_2 + \dots \nonumber \\
		&= A(t) \Phi(t,t_0).
	\end{align}
	Afirmamos que la solución a la parte homogénea de (\ref{eq: xdyn}) es $x(t) = \Phi(t,t_0)x_0$ cuya derivada con respecto al tiempo es
\begin{align}
	\frac{d}{dt} x &= \frac{d}{dt}\Phi(t,t_0)x_0 \nonumber \\
	&= A(t) \Phi(t,t_0) x_0 \nonumber \\
	&= A(t)x(t),
\end{align}
lo cual prueba la identidad $\dot x = A(t)x(t)$ dado que $x(t) = \Phi(t,t_0)x_0$. Para terminar la prueba, necesitaríamos probar que la serie (\ref{eq: ser}) converge para todo $t\geq t_0$.

La matriz $\Phi(t,t_0)$ es llamada \textbf{\emph{matriz de transición de estados}}. Dada una condición inicial $x_0$, podemos predecir $x(t)$ en (\ref{eq: xdyn}) iterando $\Phi(t,t_0)$ en el caso de que no existiera ninguna interacción con el sistema, i.e., $u(t) = 0, t\geq t_0$.

\subsection{Ejercicio}
Comprobar que
\begin{align}
	x(t) &= \Phi(t,t_0)x_0 + \int_{t_0}^t \Phi(t,\tau)B(\tau)u(\tau)d\tau  \label{eq: solx} \\
	y(t) &= C(t)\phi(t,t_0)x_0 + \int_{t_0}^t C(t)\Phi(t,\tau)B(\tau)u(\tau)d\tau + D(t)u(t), \label{eq: soly}
\end{align}
son las soluciones a

\begin{align}
	\dot x(t) &= A(t)x(t) + B(t)u(t)  \nonumber \\
	\dot y(t) &= C(t)x(t) + D(t)u(t).  \nonumber
\end{align}

\section{Solución a sistemas invariantes en el tiempo, continuos y lineales en el espacio de estados}

Comunmente conocidos como sistemas \emph{lti} (linear time invariant), son los sistemas en los que nos centraremos principalmente en el resto del curso. La matriz $\Phi(t,t_0)$ puede ser hallada analíticamente cuando $A$ es una matriz de coeficientes constantes. Si $A$ es constante, entonces podemos sacarla de las integrales en (\ref{eq: ser}), quedando
\begin{align}
	\Phi(t,t_0) := I + A \int_{t_0}^t ds_1 + A^2 \int_{t_0}^t \int_{t_0}^{s_1} ds_2ds_1 \nonumber \\ + A^3 \int_{t_0}^t \int_{t_0}^{s_1} \int_{t_0}^{s_2} ds_3ds_2ds_1 + \dots \label{eq: phi},
\end{align}
y observando que las siguientes integrales tienen solución analítica
\begin{align}
	\int_{t_0}^t ds_1 &= (t-t_0) \nonumber \\
	\int_{t_0}^t\int_{t_0}^{s_1} ds_2ds_1 &= \frac{(t-t_0)^2}{2} \nonumber \\
	\vdots \nonumber \\
	\int_{t_0}^t\int_{t_0}^{s_1} \cdots \int_{t_0}^{s_{k-2}}\int_{t_0}^{s_{k-1}}ds_k ds_{k-1} \cdots ds_2ds_1 &= \frac{(t-t_0)^k}{k!}, \nonumber
\end{align}
entonces tenemos que (\ref{eq: phi}) es calculada como
\begin{equation}
	\Phi(t,t_0) = \sum_{k=0}^{\infty} \frac{(t-t_0)^k}{k!}A^k,
\end{equation}
lo cual es familiar a la serie de Taylor de una función exponencial. Por ejemplo, para un escalar $x$, tenemos que $e^x := \sum_{k=0}^{\infty}\frac{1}{k!}x^k = 1 + x + \frac{x^2}{2} + \frac{x^3}{3!} + \dots $. De hecho, la definición de la \emph{exponencial de una matriz} es
\begin{equation}
	exp(A) = I + A + \frac{1}{2} A^2 + \frac{1}{3!} A^3 + \dots
\end{equation}
Fijemos $t_0 = 0$ por conveniencia, entonces
\begin{align}
	\Phi(t,0) &= I + tA + \frac{t^2}{2} A^2 + \frac{t^3}{3!} A^3 + \dots \nonumber \\
	&= exp(At),
\end{align}
por lo tanto, la solución a la parte homogénea (\ref{eq: xdyn}) teniendo $A$ con coeficientes constantes y fijando $t_0 = 0$ es
\begin{equation}
	x(t) = exp(At)x_0,\quad t\geq 0.
	\label{eq: xexp}
\end{equation}

Para continuar, necesitamos el siguiente resultado de álgebra lineal.
\begin{theorem}
\textbf{Forma de Jordan}. Para una matriz cuadrada $A\in\mathbb{C}^{n \times n}$, existe un cambio de base no singular $P\in\mathbb{C}^{n \times n}$ que transforma $A$ en
\begin{equation}
	J = PAP^{-1} = \begin{bmatrix}
		J_1 & 0 & 0 & \dots & 0 \\
		0 & J_2 & 0 & \dots & 0 \\
		0 & 0 & J_3 & \dots & 0 \\
		\vdots & \vdots & \vdots & \cdots & \vdots \\
		0 & 0 & 0 & \cdots & J_l
	\end{bmatrix},
\end{equation}
donde $J_i$ es el bloque de Jordan con forma
	\begin{equation}
	J_i = \begin{bmatrix}
\lambda_i & 1 & 0 & \dots & 0 \\
		0 & \lambda_i & 1 & \dots & 0 \\
		0 & 0 & \lambda_i & \dots & 0 \\
		\vdots & \vdots & \vdots & \cdots & \vdots \\
		0 & 0 & 0 & \cdots & \lambda_i
	\end{bmatrix}_{n_i\times n_i},
	\end{equation}
	en donde cada $\lambda_i$ es un autovalor de $A$, y el número $l$ de bloques de Jordan es igual al número total de autovectores independientes de $A$. La matrix $J$ es única (descontando reordenación de filas/columnas) y es llamada la \textbf{forma normal de Jordan} de $A$.
\end{theorem}

Partiendo de la observación que $A = P^{-1}JP$ también, entonces es fácil probar que 
\begin{equation}
	A^k = P^{-1} J^k P,
\end{equation}
de tal manera que podamos calcular que
\begin{align}
	exp(At) &= P^{-1}\left(\sum_{k=1}^\infty \frac{t^k}{k!} \begin{bmatrix}J_1^k & 0 & \cdots & 0 \\ 0 & J_2^k & \cdots & 0 \\ \vdots & \vdots & \cdots & \vdots \\ 0 & 0 & \cdots & J_l^k \end{bmatrix} \right) P \nonumber \\
		&= P^{-1} \begin{bmatrix}exp(J_1t) & 0 & \cdots & 0 \\ 0 & exp(J_2t) & \cdots & 0 \\ \vdots & \vdots & \cdots & \vdots \\ 0 & 0 & \cdots & exp(J_lt) \end{bmatrix} P
\end{align}

Observa que si $J$ es simplemente una matriz diagonal con los autovalores de $A$, i.e., $J_l = \lambda_l \in \mathbb{C}$, entonces $exp(J_lt) = e^{\lambda_lt} \in\mathbb{C}$ es un cálculo trivial.

Now, let us check the consequencues on the following two conditions
Ahora, veamos las consecuencias de las siguientes dos suposiciones
\begin{enumerate}
	\item $J$ es diagonal.
	\item Todos los autovalores de $A$ tienen parte real negativa.
\end{enumerate}

Sabiendo que $\lim_{t\to\infty} e^{\lambda t} \to 0$ si $\lambda \in \mathbb{R}_{<0}$, entonces tenemos que $exp(At) \to 0$ según $t\to\infty$ si las dos previas suposiciones se dan. Si echamos un vistazo a (\ref{eq: xexp}), podemos concluir que 
\begin{equation}
	\lim_{t\to\infty} x(t) \to 0,
	\label{eq: xlim}
\end{equation}
por tanto, podemos predecir la evolución de $x(t)$ con sólamente mirar los autovalores de $A$. Si $J$ no es diagonal, podremos concluir más resultados. Lo veremos en la sección siguiente a la linearización de sistemas en el espacio de estados.


\section{Linearización de sistemas en el espacio de estados}
Desafortunadamente, es realmente dificil (cuando no imposible) calcular una solución analítica para $x(t)$ e $y(t)$ para un sistema arbitrario $\Sigma$ como en (\ref{eq: sigma}). No obstante, hemos visto que sí se puede calcular una solución analítica para $x(t)$ e $y(t)$ cuando $\Sigma$ es un sistema invariante en el tiempo, continuo y lineal en el espacio de estados.

Será de gran utilidad encontrar una relación entre ambos sistemas.

Si $f(x,t)$ y $g(x,t)$ son reales analíticas en un entorno a un punto específico $(x^*,u^*)$, entonces podemos trabajar con aproximaciones de Taylor de $f(x,t)$ y $g(x,t)$ en ese mismo entorno. Cuando nos quedamos en orden uno en la aproximación es lo que se conoce como \emph{linearización}.
\begin{equation}
	\Sigma := \left.\begin{cases}
	\dot x(t) =& f(x(t),u(t)) \\ y(t) =& g(x(t),u(t))
	\end{cases}\right|_{x\approx x^*, u\approx u^*} \approx
	\begin{cases}
		x(t) &= x^* + \delta x(t) \\
		u(t) &= u^* + \delta u(t) \\
	\delta \dot x(t) &= A(t)\delta x(t) + B(t)\delta u(t) \\
	\delta y(t) &= C(t)\delta x(t) + D(t)\delta u(t)
	\end{cases}, \nonumber
\end{equation}
donde
\begin{align}
	A(t) &= \begin{bmatrix}
		\frac{\partial f_1}{\partial x_1} & \dots & \frac{\partial f_1}{\partial x_n} \\
		\vdots & \vdots & \vdots \\
		\frac{\partial f_n}{\partial x_1} & \dots & \frac{\partial f_n}{\partial x_n}
	\end{bmatrix}_{|_{x=x^*, u=u^*}} \quad
	&B(t) = \begin{bmatrix}
		\frac{\partial f_1}{\partial u_1} & \dots & \frac{\partial f_1}{\partial u_k} \\
		\vdots & \vdots & \vdots \\
		\frac{\partial f_k}{\partial u_1} & \dots & \frac{\partial f_k}{\partial u_k}
	\end{bmatrix}_{|_{x=x^*, u=u^*}} \nonumber \\
	C(t) &= \begin{bmatrix}
		\frac{\partial g_1}{\partial x_1} & \dots & \frac{\partial g_1}{\partial x_n} \\
		\vdots & \vdots & \vdots \\
		\frac{\partial g_m}{\partial x_1} & \dots & \frac{\partial g_m}{\partial x_n}
	\end{bmatrix}_{|_{x=x^*, u=u^*}} \quad
	&D(t) = \begin{bmatrix}
		\frac{\partial g_1}{\partial u_1} & \dots & \frac{\partial g_1}{\partial u_k} \\
		\vdots & \vdots & \vdots \\
		\frac{\partial g_m}{\partial u_1} & \dots & \frac{\partial g_m}{\partial u_k}
	\end{bmatrix}_{|_{x=x^*, u=u^*}}. \nonumber
\end{align}
Informalmente, estamos calculando la sensibilidad (hasta primer orden) de $f$ y $g$ cuando hacemos una variación pequeña de $x$ y $u$ alrededor de $(x^*,u^*)$. Como de pequeña ha de ser esa variación depende del sistema $\Sigma$. En particular, cuando diseñemos controladores basados en linearizar alrededor de un punto, daremos cotas para $\delta x$ y $\delta u$ de tal manera que el controlador pueda garantizar estabilidad.

\subsection{Ejercicio. Linearización del péndulo invertido}
Más adelante, veremos que podemos diseñar una entrada de control $u(t)$, i.e., una señal que ha de seguir el torque $T$ en (\ref{eq: f}) de tal manera que $\theta$ y $\dot\theta$ converjan a unos valores constantes o trayectorias deseadas.

Por ejemplo, vamos a fijar un punto constante de interés $x^* = \begin{bmatrix}\theta^* \\ 0\end{bmatrix}$, por lo que la velocidad angular se marca a cero. Esta situación corresponde a una situación de equilibrio para el ángulo $\theta$. Para hallar el $u^*(t)$ en (\ref{eq: f}) necesario para tal equilibrio necesitamos que $\frac{\mathrm{d}}{\mathrm{dt}}\left(\begin{bmatrix}\theta \\ \dot\theta \end{bmatrix}\right) = \begin{bmatrix}0 \\ 0 \end{bmatrix}$. Una inspección a la dinámica (\ref{eq: dyn}) nos responde que
\begin{equation}
	u^* = T^* = -\frac{g}{l}\sin\theta^*,
\end{equation}
por ejemplo, para una posición totalmente vertical correspondiente a $\theta^* = 0$ tenemos que $T^*=0$, i.e., $x^* = \begin{bmatrix}0\\0\end{bmatrix}$ y $u^* = 0$.

El cáclulo de las matrices $A,B,C,$ y $D$ son los Jacobianos de $(\ref{eq: f})$ y $(\ref{eq: g})$, i.e.,

\begin{align}
\frac{\partial f_1}{\partial x_1} &= 0 \nonumber \\
\frac{\partial f_1}{\partial x_2} &= 1 \nonumber \\
\frac{\partial f_2}{\partial x_1} &= \frac{g}{l}\cos\theta \nonumber \\
\frac{\partial f_2}{\partial x_2} &= -\frac{b}{ml^2} \nonumber \\
\frac{\partial f_1}{\partial u_1} &= 0 \nonumber \\
\frac{\partial f_2}{\partial u_1} &= 1 \nonumber \\
\frac{\partial g_1}{\partial x_1} &= 1 \nonumber \\
\frac{\partial g_1}{\partial x_2} &= 0 \nonumber \\
\frac{\partial g_1}{\partial u_1} &= 0, \nonumber
\end{align}
por lo que podemos llegar a
\begin{align}
	\frac{\mathrm{d}}{\mathrm{dt}}\left(\begin{bmatrix}\delta\theta \\ \dot\delta\theta \end{bmatrix}\right) &= \begin{bmatrix}0 & 1 \\ \frac{g}{l}\cos\theta & -\frac{b}{ml^2} \end{bmatrix}_{|_{\theta=\theta^*}} \begin{bmatrix}\delta\theta \\ \dot\delta\theta \end{bmatrix} + \begin{bmatrix}0 \\ 1 \end{bmatrix} \delta T \nonumber \\
		\delta y &= \begin{bmatrix}1 & 0\end{bmatrix}\begin{bmatrix}\delta\theta \\ \dot\delta\theta \end{bmatrix} + 0 \, \delta T,
\end{align}
para modelar una aproximación a la dinámica de $x(t)$ y la salida $y(t)$ alrededor de los puntos $x^*$ y $u^*$.

\section{(Internal or Lyapunov) Stability}
\label{sec: sta}

Decimos que el sistema lineal (\ref{eq: linsys}) \emph{en el sentido de Lyapunov}
\begin{enumerate}
	\item es \emph{(marginalmente) estable} si para cada condición inicial $x_0$, entonces $x(t) = \Phi(t,t_0) x_0$ está acotada uniformamente para todo $t>t_0$.
	\item es \emph{asintóticamente estable} si admeás $x(t) \to 0$ según $t\to\infty$.
	\item es \emph{exponencialmente estable} si además $||x(t)|| \leq c e^{\lambda(t-t_0)}||x(t_0)||$ para algunas constantes $c,\lambda > 0$.
	\item is \emph{inestable} si no es marginalmente estable.
\end{enumerate}

%In control, it is very common to focus on \emph{error signals}, e.g., $e(t) := x(t) - x^*(t)$, where $x^*(t)$ is a trajectory goal. Note that if $x^*$ is constant, then $\dot e(t) = \dot x(t)$, and this is why we focus on having $x(t) \to 0$ as $t\to\infty$ in the above definitions for (\ref{eq: sigmalin}).

Centrémonos en sistemas \emph{lti}, es decir, cuando $A$ tiene coeficientes constantes o $\Phi(t,t_0) = e^{A(t-t_0)}$. Entonces, podemos establecer una clara relación entre los autovalores de $A$ y las definiciones de estabilidad en el sentido de Lyapunov únicamente inspeccionando la solución a $\dot x(t) = Ax(t)$ dada por (\ref{eq: solx}).

El sistema $\dot x(t) = Ax(t)$
\begin{enumerate}
	\item es marginalmente estable si y solo si todos los autovalores de $A$ tienen parte real negativa. Si algún autovalor tiene parte real nula, entonces su bloque de Jordan ha de ser $1\times 1$.
	\item es asintóticamente estable si y solo si todos los autovales de $A$ tienen estrictamente parte real negativa.
	\item es exponencialmente estable si es asintóticamente estable.
	\item es inestable si y solo si al menos un autovalor de $A$ tiene parte real positiva, o al menos uno de los autovalores con parte real nula tiene un bloque de Jordan mayor de $1\times 1$.
\end{enumerate}

Comprobando las soluciones (\ref{eq: solx})-(\ref{eq: soly}), podemos decir que si $A$ tiene coeficientes constantes y $\dot x = Ax$ es asintóticamente estable, entonces $x(t) \to \int_{t_0}^t e^{A(t-\tau)}B(\tau)u(\tau)d\tau$ según $t\to\infty$. 

\subsection{Estabilidad local de sistemas linearizados}
Si $x(t)$ es asintóticamente (exponencialmente) estable en $\dot x(t) = Ax(t)$, entonces, existe una única $P$ que satisface la \emph{ecuación de Lyapunov}
\begin{equation}
A^TP + PA = -Q, \quad \forall Q \succ 0.
	\label{eq: lya}
\end{equation}
Uno puede probar (\ref{eq: lya}) si considera
\begin{equation}
	P:= \int_0^\infty e^{A^Tt}Qe^{At}dt.
	\label{eq: P}
\end{equation}
Pista: Primero, sustituye $P$ en (\ref{eq: lya}), y después verifica el cálculo  $\frac{\mathrm{d}}{\mathrm{dt}}\left(e^{A^Tt}Qe^{At}\right)$. Si uno prueba que $P$ es única, entonces $P$ ha de ser positiva definida acorde a su definición (\ref{eq: P}).

Ahora vamos a considerar un sistema continuo, autónomo y no lineal en general
\begin{equation}
	\dot x(t) = f(x(t)), \quad x\in\mathbb{R}^n,
	\label{eq: non}
\end{equation}
con un punto de equilibrio $x^*\in\mathbb{R}^n$, i.e, $f(x^*) = 0$. La dinámica de $x(t)$ puede ser aproximada considerando $x(t) = x^* + \delta x(t)$ donde 
\begin{equation}
	\dot{\delta x(t)} = A\,\delta x(t), \quad A:=\frac{\partial f(x)}{\partial x}.
	\label{eq: delta}
\end{equation}

¿Cómo de buena es esta aproximación?

\begin{theorem}
	\label{thm: tayl}
	Asume que $f(x)$ is dos veces diferenciable. Si (\ref{eq: delta}) es exponencialmente estable, entonces, existe un entorno $\mathcal{B}$ alrededor de $x^*$ y constantes $c, \lambda > 0$ tal que para cada solución $x(t)$ del sistema (\ref{eq: non}) que empiece con $x(t_0)\in\mathcal{B}$, tenemos que
	\begin{equation}
	||x(t) - x^*|| \leq ce^{\lambda(t-t_0)} ||x(t_0) - x^*||, \quad \forall t\geq t_0.
	\end{equation}
\end{theorem}

\subsubsection{¿Cómo de grande es $\mathcal{B}$? ¿Podemos estimarlo? Esbozo de la prueba del Teorema \ref{thm: tayl}}

Como $f$ es dos veces diferenciable, de su desarrollo de Taylor tenemos que
\begin{equation}
	r(x) := f(x) - (f(x^*) + A(x - x^*)) = f(x) - A\,\delta x = O(||\delta x||^2),
\end{equation}
lo cual significa que existe una constante $c$ y una bola $\bar B$ alrededor de $x^*$ tal que 
\begin{equation}
	||r(x)|| \leq c||\delta x||^2, \quad x\in\bar B.
\end{equation}
Si el sistema linearizado es exponencialmente estable, tenemos que
\begin{equation}
A^TP + PA = -I.
\end{equation}
Ahora considera la siguiente señal escalar
\begin{equation}
	v(t) := (\delta x)^T P \delta x, \quad \forall t\geq 0.
\end{equation}
Observa que $\delta x(t) = x(t) - x^*$, entonces $\dot{\delta x(t)} = \dot x(t) = f(t)$. Por lo tanto, la derivada con respecto del tiempo de $v(t)$ satisface
\begin{align}
	\dot v &= f(x)^T P \delta x + (\delta x)^T P f(x) \nonumber \\
	&= (A\delta x + r(x))^T P \delta x + (\delta x)^T P (A\delta x + r(x)) \nonumber \\
	&= (\delta x)^T(A^T P + PA)\delta x + 2(\delta x)^T P r(x) \nonumber \\
	&= -||\delta x||^2 + 2(\delta x)^T P r(x) \nonumber \\
	&\leq -||\delta x||^2 + 2 ||P||\, ||\delta x|| \, ||r(x)||.
\end{align}

Sabemos que $v(t)$ es positiva excepto cuando $\delta x = 0$. Si podemos garantizar que $\dot v(t) < 0$ y que $\dot v(t) = 0$ solo cuando  $\delta x = 0$, entonces $v(t) \to 0$ as $t\to\infty$, lo cual implica que  $\delta x(t) \to 0$ as $t\to\infty$.

Ahora, si $x\in\mathcal{\bar B}$, entonces

\begin{equation}
	\dot v \leq -\Big(1 - 2c\,||P||\,||\delta x||\Big)||\delta x||^2,
\end{equation}
Por lo tanto, si la desviación  $\delta x$ es suficientemente pequeña, i.e., 
\begin{equation}
||\delta x|| < \frac{1}{2c||P||},
\end{equation}
entonces  $\dot v(t) < 0$ si $\delta x(0) \neq 0$ y $\delta x(0) < \frac{1}{2c||P||}$.

Podemos concluir que una estimación de $\mathcal B$ es
\begin{equation}
	\mathcal{B} := \{ \delta x : ||\delta x|| < \frac{1}{2c||P||} \}.
	\label{eq: Bregion}
\end{equation}

\section{Controlabilidad}
\subsection{Subespacios alcanzables y controlables}
Recordemos que cueando aplicamos una entrada genérica $u(\cdot)$ a (\ref{eq: linsys}), transferimos el sistema de un estado $x(t_0):=x_0$ a un estado $x(t_1):=x_1$, que además podemos calcular con la expresión
\begin{equation}
	x_1 = \Phi(t_1,t_0)x_0 + \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)u(\tau)d\tau,
\end{equation}
donde recordemos que $\Phi(\cdot)$ es la matriz de transición de estados del sistema.

Preguntas:
\begin{enumerate}
	\item ¿Qué estados puedo alcanzar desde $x_0$?
	\item ¿Existe siempre una entrada $u(\cdot)$ que transfiera un estado arbitrario $x_0$ a otro $x_1$?
\end{enumerate}

Estas dos preguntas llevan a acuñar las definiciones de (sub)espacios alcanzables y controlables.

\begin{definition}[Subespacio alcanzable]
	Dados dos instantes de tiempo $t_1>t_0\geq 0$, el subespacio alcanzable (o controlable desde el origen) $\mathcal{R}[t_0,t_1]$ consiste en todos los estados $x_1$ por los que existe una entrada $u:[t_0,t_1]\to \mathbb{R}^k$ que transfiere el estado $x_0 = 0$ a  $x_1 \in\mathbb{R}^n$; i.e.,
	\begin{equation}
		\mathcal{R}[t_0,t_1] := \Big\{x_1\in\mathbb{R}^n : \exists u(\cdot),\, x_1 = \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)u(\tau)d\tau \Big\}. \label{eq: rs}
	\end{equation}
\end{definition}

\begin{definition}[Subespacio controlable]
	Dados dos instantes de tiempo $t_1>t_0\geq 0$, el subespacio controlable (or controlable hacia el origen) $\mathcal{C}[t_0,t_1]$ consiste en todos los estados $x_0$ por los que existe una entrada $u:[t_0,t_1]\to \mathbb{R}^k$ que transfiera un estado $x_0\in\mathbb{R}^n$ a $x_1 = 0$; i.e.,
	\begin{equation}
		\mathcal{C}[t_0,t_1] := \Big\{x_0\in\mathbb{R}^n : \exists u(\cdot),\, 0 = \Phi(t_1,t_0)x_0 + \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)u(\tau)d\tau \Big\}.
	\end{equation}
\end{definition}

¿Cómo podemos calcular $\mathcal{R}[t_0,t_1]$ y $\mathcal{C}[t_0,t_1]$? Para ello vamos a introducir y explotar las siguientes dos matrices llamadas \emph{Gramianos}.

\begin{definition}[Gramianos de alcanzabilidad y controlabilidad]
	\begin{align}
		W_R(t_0,t_1) &:= \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)B(\tau)^T\Phi(t_1,\tau)^Td\tau \\
		W_C(t_0,t_1) &:= \int_{t_0}^{t_1} \Phi(t_0,\tau)B(\tau)B(\tau)^T\Phi(t_0,\tau)^Td\tau 
	\end{align}
\end{definition}

\begin{theorem}
Dados dos instantes de tiempo $t_1 > t_0 \geq 0$,
	\begin{align}
		\mathcal{R}[t_0,t_1] &= \text{Im}\{W_R(t_0,t_1)\} \label{RI} \\
		\mathcal{C}[t_0,t_1] &= \text{Im}\{W_C(t_0,t_1)\} \label{CI},
	\end{align}
	donde $\text{Im}\{A\}:= \Big\{y\in\mathbb{R}^m: \exists x\in\mathbb{R}^n, y = Ax\Big\}$ para una matriz $A\in\mathbb{R}^{m\times n}$.
\end{theorem}
\begin{proof}
	Solo vamos a probar (\ref{RI}) porque (\ref{CI}) tiene una prueba similar.
	Necesitamos mostrar ambas implicaciones: primero, si $x_1 \in \text{Im}\{W_R(t_0,t_1)$, entonces $x_1 \in \mathcal{R}[t_0,t_1]$; segundo, si $x_1 \in \mathcal{R}[t_0,t_1]$ entonces $x_1 \in \text{Im}\{W_R(t_0,t_1)$.\\
	Cuando  $x_1 \in \text{Im}\{W_R(t_0,t_1)$, existe un vector $\mu_1\in\mathbb{R}^n$ tal que
	\begin{equation}
	x_1 = W_R(t_0,t_1)\eta_1.
	\end{equation}
	Escoge $u(\tau) = B(\tau)^T\Phi(t_1, \tau)^T\eta_1$, y sustitúyelo en (\ref{eq: rs}), entonces tenemos que 
	\begin{equation}
	x_1 = \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau) B(\tau)^T\Phi(t_1, \tau)^T \eta_1d\tau = W_R(t_0,t_1)\eta_1.
	\end{equation}
	Cuando $x_1 \in \mathcal{R}[t_0,t_1]$, existe una entrada $u(\cdot)$ para la cual 
	\begin{equation}
		x_1 = \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)u(\tau)d\tau.
		\label{x1}
	\end{equation}
	Si (\ref{x1}) es en $\text{Im}\{W_R(t_0,t_1)\}$, entonces $x_1^T\mu = 0, \, \mu \in \text{Ker}\{W_R(t_0,t_1)\}$\footnote{If $x\in\text{Ker}\{A^T\}$, por lo que $A^Tx = 0$. Si $y\in\text{Im}\{A\}$, entonces  $y = A\eta$. Por lo tanto, $x^Ty = x^TA\eta = \eta^TA^Tx = \eta \cdot 0 = 0$. Observa que $W_R^T = W_R$ por definción.} Vamos a calcular 
	\begin{equation}
		x_1^T\mu = \int_{t_0}^{t_1}u(\tau)^TB(\tau)^T\Phi(t_1,\tau)^T\mu \, d\tau. \label{eq: x1eta1}
	\end{equation}
	Y observando que 
	\begin{align}
	\mu \in \text{Ker}\{W_R(t_0,t_1)\} \implies \mu^TW_R(t_0,t_1)\mu &= 0 \nonumber \\ &= \int_{t_0}^{t_1}\mu^T \Phi(t_1,\tau)B(\tau)B(\tau)^T\Phi(t_1,\tau)^T \mu \, d\tau \nonumber \\ &= \int_{t_0}^{t_1} ||B(\tau)^T\Phi(t_1,\tau)^T \mu||^2 d \tau,
	\end{align}
	obtenemos que $B(\tau)^T\Phi(t_1,\tau)^T \mu  = 0$, llevando a (\ref{eq: x1eta1}) ser igual a cero.
\end{proof}
\begin{remark}
	Observa que hemos probado que $u(\tau) = B(\tau)^T\Phi(t_1,\tau)^T \eta_1$ puede ser como una entrada de control para transferir $x_0 = 0$ a $x_1\in\mathbb{R}^n$ en un tiempo finito $(t_1 - t_0)$. De hecho, esta es la señal de control \emph{en lazo abierto de mínima energía}.
\end{remark}
Vamos a ver este hecho en más detalle. Considera otra señal de control  $\bar u(t)$ tal que 
\begin{equation}
x_1 = \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)u(\tau)d\tau = \int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)\bar u(\tau)d\tau.
\end{equation}
Para que sea cierto, debemos tener
For this to hold, we must have
\begin{equation}
	\int_{t_0}^{t_1} \Phi(t_1,\tau)B(\tau)v(\tau) \, d\tau = 0,
	\label{eq: ve}
\end{equation}
donde $v(\tau) = u(\tau) - \bar u(\tau)$.
Vamos a ver la energía asociada a $\bar u$
\begin{align}
\int_{t_0}^{t_1}||\bar u(\tau)||^2 d\tau &= \int_{t_0}^{t_1} || B(\tau)^T\Phi(t_1,\tau)^T \eta_1 + v(\tau)||^2 d\tau \nonumber \\ 
&= \eta_1^T W_R(t_0,t_1)\eta_1 + \int_{t_0}^{t_1} ||v(\tau)||^2 d \tau + 2\eta_1^T \int_{t_0}^{t_1}B(\tau)\Phi(t_1,\tau)v(\tau) d \tau,
\end{align}
donde el tercer término es cero por (\ref{eq: ve}). Por lo tanto, si $\bar u(t)$ difiere $v(t)$ de $u(t)$, gastará $\int_{t_0}^{t_1} ||v(\tau)||^2 d\tau$ más energía que $u(t)$.

\subsection{Matriz de controlabilidad para un sistema lti}

Consideremos un sistema lineal (\ref{eq: linsys}) con $A$ y $B$ con coeficientes constantes.

El teorema de Cayley-Hamilton nos permite escribir
\begin{equation}
	e^{At} = \sum_{i=0}^{n-1}\alpha_i(t)A^i, \quad \forall t\in\mathbb{R},
\end{equation}
para algunas funciones escalares apropiadas $\alpha_i(t)$. Tenemos también que si $A$ y $B$ tienen coeficientes constantes, entonces
\begin{align}
	x_1 &= \int_{0}^{t_0-t_1} e^{At}Bu(t) dt \nonumber \\
	&= \sum_{i=0}^{n-1} A^iB \Big(\int_{0}^{t_1-t_0}\alpha_i(t)u(t)dt \Big) \nonumber \\
	&= \mathcal{C} \begin{bmatrix}\int_{0}^{t_1-t_0}\alpha_0(t)u(t)dt \\ \vdots \\ \int_{0}^{t_1-t_0} \alpha_{n-1}(t)u(t)dt \end{bmatrix},
\end{align}
donde
\begin{equation}
\mathcal{C}:=\begin{bmatrix}B & AB & A^2B & \cdots & A^{n-1}B
\end{bmatrix}_{n\times (kn)},
	\label{eq: conmat}
\end{equation}
es la llamada matrix de controlabilidad del sistema lti.
\begin{remark}Observa que $\mathcal{C}[t_0,t_1]$ y $\mathcal{C}$  son diferentes objetos. El primero es un (sub)espacio, mientras que el segundo es una matriz.
\end{remark}

Observa que acabamos de probar que la imagen de $\mathcal{C}$ es la misma que la imagen de $W_R(t_0,t_1)$. La siguiente afirmación más general puede probarse también:
\begin{theorem}
	\label{thm: spcon}
Dados dos instantes de tiempo $t_0, t_1$, con $t_1 > t_0$, tenemos que
	\begin{equation}
		\mathcal{R}[t_0,t_1] = \text{Im}\{W_R(t_0,t_1)\} = \text{Im}\{\mathcal{C}\} = \text{Im}\{W_C(t_0,t_1)\} = \mathcal{C}[t_0,t_1],
	\end{equation}
\end{theorem}

Podemos extraer dos importantes consecuencias del Teorema \ref{thm: spcon} para sistemas lti. ¡Observa que $\text{Im}\{\mathcal{C}\}$ no depende de ninguna variable tiempo!

\begin{enumerate}
	\item \emph{Reversibilidad temporal}: Si uno puede alcanzar $x_1$ desde el origen, entonces uno puede alcanzar el origen desde $x_1$. Es decir, los subespacios de alcanzabilidad y controlabilidad son el mismo subespacio.
	\item \emph{Escalado de tiempo}: La alcanzabilidad y la controlabilidad no dependen del tiempo. Si uno puede transferir el estado de $x_0$ and $x_1$ en $t$ segundos, entonces también puedes hacerlo en $\bar t \neq t$ segundos.
\end{enumerate}

\begin{definition}
	Dados dos instantes de tiempo $t_1 > t_0 \geq 0$, el par $(A,B)$ del sistema (\ref{eq: linsys}) se dice \emph{alcanzable} en $[t_0, t_1]$ si $\mathcal{R}[t_0,t_1] = \mathbb{R}^n$. Es decir, si podemos alcanzar cualquier estado en tiempo finito partiendo desde el origen.
\end{definition}

\begin{definition}
	\label{def: con}
	Dados dos instantes de tiempo $t_1 > t_0$, el par del sistema (\ref{eq: linsys}) se dice \emph{controlable} en $[t_0, t_1]$ si $\mathcal{C}[t_0,t_1] = \mathbb{R}^n$. Es decir, si podemos alcanzar el origen partiendo desde cualquier estado en tiempo finito.
\end{definition}

\subsection{Tests de controlabilidad}
El siguiente teorema es el resultado de combinar la Definición \ref{def: con} con el Teorema \ref{thm: spcon}:
\begin{theorem}
	El par (constante) $(A,B)$ es controlable si y solo si el rango de $\mathcal{C}$ es $n$.
\end{theorem}

El siguiente teorema se puede comprobar numéricamente a partir de los siguientes resultados.
\begin{theorem}
	\label{thm: atbt}
	El par (constante) $(A,B)$ es controlable si y solo si no existe ningún autovector de $A^T$ en el kernel de $B^T$.
\end{theorem}
El siguiente teorema es una reescritura del anterior.
\begin{theorem}
El par (constante) $(A,B)$ es controlable si y solo si el dango de $\begin{bmatrix}A-\lambda I & B\end{bmatrix}$ es $n$.
\end{theorem}

\begin{remark}
	Observa que el tener un sistema asintóticamente estable no implica el tener 
	un sistema lti controlable. Por ejemplo, 
\begin{equation}
	\dot x = \begin{bmatrix}-3 & 0 \\ 0 & -7\end{bmatrix}x + \begin{bmatrix}0 \\ 1\end{bmatrix}u, \quad x\in\mathbb{R}^2, u\in\mathbb{R}.
\end{equation}
	El kernel de $B^T$ es generado por $\begin{bmatrix}1 \\ 0\end{bmatrix}$, el cual es proporcional a un autovector de $A = A^T$. Entonces, el sistema no es controlable acorde al teorema \ref{thm: atbt}. Observa, que no tenemos autoridad ninguna sobre $x_1$ a través de $u$. Sin embargo, es asintóticamente estable. Uno puede ver que $x_{\{1,2\}}(t) \to 0$ según $t\to\infty$ cuando $u = 0$. Recuerda que la controlabilidad trata de transferir estados en \textbf{tiempo finito}.
\end{remark}

\section{Estabilización de un sistema lti por realimentación basado en el test de Lyapunov}
\subsection{Test de Lyapunov para la estabilización de un sistema lti}
\begin{definition}
	Si el sistema (\ref{eq: linsys}) es lti, entonces es estabilizable si existe una entrada $u(t)$ para cualquier $x(0)$ tal que $x(t)\to 0$ as $t\to\infty$.
\end{definition}
Esta definición es una versión de \emph{sistema controlable} pero para tiempo infinito. En el siguiente teorema veremos que \emph{estabilizable} es menos restrictivo que \emph{controlable}.

\begin{theorem}
	Si el sistema (\ref{eq: linsys}) es lti, entonces es estabilizable si y solo si todos los autovectores de $A^T$ correspondientes a autovalores con parte real no negativa pertenecen al kernel de $B^T$.
\end{theorem}

La proyección de $x(t)$ sobre el espacio generado por los autovectores de $A^T$ asociados a autovalores con parte real negativa van a cero sin necesidad de la \emph{asistencia} de ninguna entrada. Entonces, la entrada $u(t)$ debe asistir a las proyecciones de $x(t)$ en el resto de autovectores de $A^T$. Por ejemplo,

\begin{equation}
	\dot x = \begin{bmatrix}-3 & 0 \\ 0 & 7\end{bmatrix}x + \begin{bmatrix}0 \\ 1\end{bmatrix}u, \quad x\in\mathbb{R}^2, u\in\mathbb{R},
\end{equation}
mientras que no tenemos ninguna \emph{autoridad} sobre $x_1(t)$, podemos emplear $u(t)$ para lleva a $x_2(t)$ a cero de tal manera que $x(t)\to 0$ según $t\to\infty$.
\begin{theorem}
	Si el sistema (\ref{eq: linsys}) es lti, entonces es estabilizable si y solo si hay una matriz positiva definida $P$ a la siguiente desigualdad
	\begin{equation}
	AP + PA^T - BB^T \prec 0
		\label{eq: lb}
	\end{equation}
\end{theorem}
\begin{proof}
	Solo vamos a ver una dirección de la prueba. No confundir (\ref{eq: lb}) con la ecuación de Lyapunov\footnote{Observa el orden de las matrices traspuestas, y observa también el signo opuesto de $-BB^T$ y $+I$ en las dos ecuaciones.} $PA+A^TP \prec -I$ en (\ref{eq: lya}).

Conisdera $x$ como un autovector asociado al autovalor $\lambda$ de $A^T$ con parte real no negativa. Entonces,
	\begin{equation}
	x^*(AP+PA^T)x < x^*BB^Tx = ||B^Tx||^2,
		\label{eq: aux}
	\end{equation}
	donde $x^*$ es el complejo conjugado de $x$. Pero el lado izquierdo de (\ref{eq: aux}) es igual a 
	\begin{equation}
		(A^T(x^*)^T)^TPx + x^*PA^Tx = \lambda^*x^*Px + \lambda x^*Px = 2\text{Real}\{\lambda\}x^*Px.
	\end{equation}
	Como $P$ es positiva definida, y $\text{Real}\{\lambda\} \geq 0$, podemos concluir que 
\begin{equation}
0 \leq 2\text{Real}\{\lambda\}x^*Px < ||B^Tx||^2,
\end{equation}
y por tanto $x$ debe pertenecer al kernel de $B$, si no tendríamos que 
\begin{equation}
0 \leq 2\text{Real}\{\lambda\}x^*Px < 0,
\end{equation}
y eso no es posible.
\end{proof}

\subsection{Controlador por realimentación de estados}
Realimentación de estados implica el escoger una señal de entrada que dependa únicamente de los estados del sistema, es decir, diseñar una
\begin{equation}
u(t) = -Kx(t),
	\label{eq: kx}
\end{equation}
donde $K\in\mathbb{R}^{n\times k}$, tal que $x(t) \to 0$ en (\ref{eq: linsys}) exponencialmente rápido según $t\to\infty$.

Define la ganancia matriz de control
\begin{equation}
	K:=\frac{1}{2}B^TP^{-1}, \label{eq: K}
\end{equation}
donde $P$ se calcula en (\ref{eq: lb}) si y solo si un sistema lti es estabilizable. Por lo tanto, podemos rescribir (\ref{eq: lb}) como
\begin{equation}
	(A - \frac{1}{2}BB^TP^{-1})P + P(A - \frac{1}{2}BB^TP^{-1})^T = (A-BK)P+P(A-BK)^T \prec 0,
\end{equation}
y multiplicando a la izquierda y derecha por $Q:=P^{-1}$ tenemos que
\begin{equation}
	Q(A-BK)+(A-BK)^TQ \prec 0,
\end{equation}
la cual es una ecuación de Lyapunov. Por lo tanto, podemos concluir que $(A-BK)$ tiene todos sus autovalores \emph{estables}, esto es, si uno escoge la entrada
\begin{equation}
	u = -Kx = -\frac{1}{2}B^TP^{-1}x, \label{eq: conK}
\end{equation}
en el sistema lti estabilizable, entonces $x(t) \to 0$ exponencialmente rápido según $t\to\infty$.

Encontrar la matrix $P$ en (\ref{eq: K}) requiere resolver la \emph{linear matrix inequality} (LMI) en (\ref{eq: lb}). Para ello existen herramientas numéricas \emph{LMI solvers} disponibles en Matlab o Python.

Si el sistema lti es controlable (recordemos que es más restrictivo que estabilizable), la matriz $K$ en (\ref{eq: kx}) puede explotar el Teorema \ref{thm: atbt}. Es decir, podemos encontrar una matriz $K$ tal que $(A-BK)$ tenga sus autovalores donde nosotros queramos por diseño. Por ejemplo, a través del Teorema de Ackermann.
\begin{theorem}
	Si el sistema lti es controlable, entonces $(A-BK)$ tiene como autovalores un conjunto deseado $\Lambda$ si
	\begin{equation}
		K = \begin{bmatrix}0 & \dots & 0 & 0 & 1\end{bmatrix}\mathcal{C}^{-1} \Delta(A),
	\end{equation}
	en donde $\mathcal{C}$ es la matrix de controlabilidad (\ref{eq: conmat}) y $\Delta$ es el polinomio característico que satisface $\Lambda$.
\end{theorem}


\section{Observabilidad en sistemas lti}
In this section we will consider only the following linear system
\begin{equation}
	\Sigma_{\text{lti}} := \begin{cases}
	\dot x(t) &= Ax(t) + Bu(t) \\
		y(t) &= Cx(t) + Du(t)
	\end{cases}.
\label{eq: sigmalinc}
\end{equation}
\subsection{Unobservable subspace and the observability Gramian}
\begin{definition}
	The \emph{unobservable} subspace $\mathcal{UO}$ of system (\ref{eq: sigmalinc}) consists of all the states $x_0\in\mathbb{R}^n$ such that
	\begin{equation}
	C e^{A} x_0 = 0.
		\label{eq: ce}
	\end{equation}
\end{definition}
This definition is motivated by the following facts.
Recall that from (\ref{eq: soly}) we have that
\begin{align}
	y(t) &= Ce^{At}x_0 + \int_0^tCe^{A(t-\tau)}Bu(\tau)d\tau + Du(t) \nonumber \\
	\tilde y(t) &:= y(t) - \int_0^tCe^{A(t-\tau)}Bu(\tau)d\tau - Du(t) = Ce^{At}x_0. \label{eq: y}
\end{align}
On the left hand side of (\ref{eq: y}) we have a pair input/output, and on the right hand side of (\ref{eq: y}) we have the initial state $x_0$. From (\ref{eq: y}) we can observe two interesting properties:
\begin{enumerate}
	\item When a particular $x_0$ is compatible with an input/output pair, then every initial state of the form $x_0 + x_u, \, x_u\in\mathcal{UO}$, is also compatible with the same input/output pair.
	\item When $\mathcal{UO}$ contains only the zero vector, then there exists at most one initial state $x_0$ that is compatible with the input/output pair.
\end{enumerate}

\begin{definition}
	The system (\ref{eq: sigmalinc}) is observable if its $\mathcal{UO}$ contains only the zero vector.
\end{definition}

\begin{definition}
	Given two times $t_1>t_0\geq 0$, the observability Gramian is defined by
	\begin{equation}
		W_O(t_0,t_1) := \int_{t_0}^{t_1}e^{A^T(\tau - t_0)} C^T Ce^{A(\tau - t_0)}d\tau
	\end{equation}
\end{definition}
There is difference w.r.t. the controllability Gramian, the transposes appear on the left for the observability Gramian, whereas the transposes appear on the right for the controllability Gramian.
Starting with (\ref{eq: ce}), it can be shown that
\begin{equation}
	\operatorname{Ker}W_O(t_0,t_1) = \mathcal{UO}.
\end{equation}

\subsection{Observability tests}
The following can be proven formally by applying the theorem of Cayley-Hamilton\footnote{To see why we stop at $(n-1)$.}. Let us now check the sensibility of $y$ and its time derivatives with respect to $x$ when\footnote{Note that $B$ and $D$ do not play any role for the observability, only $A$ and $C$.} $u(t)=0$
\begin{align}
	y(t) = Cx(t) &\implies \dot y(t) = C\dot x(t) = CAx(t) \implies \ddot y(t) = C A^2 x(t) \quad \dots \nonumber \\ &\implies \frac{\mathrm{d}^{n-1}y}{\mathrm{dt}^{n-1}} = CA^{n-1}x(t), \nonumber
\end{align}
If we do not want to loose any information of the signal $x(t)$, then the matrix
\begin{equation}
	\mathcal{O} = \begin{bmatrix}C \\ CA \\ \vdots \\ CA^{n-1}\end{bmatrix}_{(kn)\times n}, \label{eq: O}
\end{equation}
must be full column rank. We, then, introduce the following equivalent results.
\begin{theorem}
	The system (\ref{eq: sigmalinc}) is observable if and only if the rank of $\mathcal{O}$ equals $n$.
\end{theorem}
\begin{theorem}
The system (\ref{eq: sigmalinc}) is observable if and only if no eigenvector of $A$ is in the kernel of $C$.
\end{theorem}

Note that from (\ref{eq: O}) we can derive a \emph{controllability} test
\begin{equation}
	\mathcal{O}^T = \begin{bmatrix}C^T & A^TC^T & \cdots & (A^{n-1})^TC^T \end{bmatrix}_{n \times (kn)}, 
\end{equation}
from which we can derive from the following \emph{dual} system constructed from (\ref{eq: sigmalinc})
\begin{equation}
	\Sigma_{\text{dual}} := \begin{cases}
		\dot{\bar x}(t) &= A^T \bar x(t) + C^T \bar u(t) \\
		\bar y(t) &= B^T\bar x(t) + D^T\bar u(t)
	\end{cases},
\label{eq: sigmadual}
\end{equation}
then, we have the following result
\begin{theorem}
	The system (\ref{eq: sigmalinc}) is controllable if and only if (\ref{eq: sigmadual}) is observable.
\end{theorem}
Therefore, we only need to study the controllability of the dual system (\ref{eq: sigmalinc}) to conclude about its observability.

\section{State estimation for linear time invariant systems}
The simplest estimator consists of a copy of the system (\ref{eq: sigmalinc})
\begin{equation}
	\Sigma_{\text{estimator}} := \begin{cases}
		\dot{\hat x}(t) &= A \hat x(t) + B u(t) \\
		\hat y(t) &= C\hat x(t) + D u(t)
	\end{cases},
\label{eq: sigmaest}
\end{equation}
and let us define the error signal $e(t) := \hat x(t) - x(t)$. Now, let us check the dynamics of the error signal
\begin{equation}
	\dot e(t) = \dot{\hat x}(t) - \dot x(t) = A\hat x + Bu - Ax - Bu = Ae(t),
\end{equation}
therefore $e(t)\to 0$ as $t\to\infty$ exponentially fast if $A$ is a stability matrix for every input signal $u(t)$.

What if $A$ is not a stability matrix? Then, consider the following system
\begin{equation}
	\Sigma_{\text{estimator2}} := \begin{cases}
		\dot{\hat x}(t) &= A \hat x(t) + B u(t) - L(\hat y(t) - y(t)) \\
		\hat y(t) &= C\hat x(t) + D u(t)
	\end{cases},
\label{eq: sigmaest2}
\end{equation}
where we have \emph{two inputs} $u$ and $(\hat y - y)$, and $L\in\mathbb{R}^{n\times m}$ is a matrix gain. Note that the signal $y$ comes from (\ref{eq: sigmalinc}). Now, let us see the dynamics of the error signal
\begin{equation}
	\dot e = A\hat x + Bu - L(\hat y - y) - (Ax + Bu) = (A-LC)e,\label{eq: ed} 
\end{equation}
thus, if we can make $(A-LC)$ a stability matrix, then $e(t)\to 0$ as $t\to\infty$ exponentially fast for every input signal $u(t)$. 

Sometimes, it is not possible to find such a $L$ because of the structure of $C$ (something similar happened for $K$ and $B$ for the stabilizability and controllability of (\ref{eq: sigmalin})). Then we have a similar result about \emph{detectatbility}.
\begin{theorem}
	The system (\ref{eq: sigmalinc}) is \emph{detectable} if and only if every eigenvector of $A$ corresponding to a non stable eigenvalue is not in the kernel of $C$.
\end{theorem}
Remember, a system is detectable if its dual is stabilizable.
\begin{theorem}
	When a pair $(A,C)$ is detectable, it is always possible to find $L$ such that $(A-LC)$ is a stability matrix.
\end{theorem}
\begin{theorem}
	When a pair $(A,C)$ is observable, it is always possible to find $L$ such that $(A-LC)$ is a stability matrix with an arbitrary set of stable eigenvalues.
\end{theorem}
In such a case, we can always compute $L$ as we have computed $K$ as in (\ref{eq: K}) for controllable systems by analyzing the dual system of (\ref{eq: sigmalinc}). Note that in such a computation, since we are dealing with the dual system, the matrix gain $K$ will be $L^T$.

\section{Stabilization of linear time invariant systems through output feedback}
If $C$ is not invertible, then we do not have \emph{direct access} to the states $x$ in (\ref{eq: sigmalinc}); therefore we cannot apply the control input $u = -Kx$ as in (\ref{eq: conK}).

What if (\ref{eq: sigmalinc}) is observable, or at least detectable? Then, we are going to show that we can employ
\begin{equation}
	u = -K \hat x, \label{eq: uh}
\end{equation}
where $\hat x$ are the states of our estimator (\ref{eq: sigmaest2}), as a control action to stabilize (\ref{eq: sigmalinc}) around the origin. Let us apply (\ref{eq: uh}) in (\ref{eq: sigmalinc}), therefore we have that
\begin{equation}
	\dot x = Ax - BK\hat x = Ax - BK(e + x) = (A -BK)x -BKe,
\end{equation}
that together with (\ref{eq: ed}) give us the following autonomous system
\begin{equation}
	\begin{bmatrix}\dot x \\ \dot e\end{bmatrix} = \begin{bmatrix}A-BK & -BK \\ 0 & A-LC\end{bmatrix}\begin{bmatrix}x \\ e\end{bmatrix},
\end{equation}
which is exponentially stable since $(A-BK)$ and $(A-LC)$ are stability matrices (if our system (\ref{eq: sigmalinc}) is at least stabilizable and detectable) and the triangular structure of the state-transition matrix.

