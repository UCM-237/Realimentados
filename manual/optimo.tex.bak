\chapter{Introducción al control óptimo}
\section{El Regulador Cuadrático Lineal (LQR)}
En los capítulos anteriores hemos visto como es posible estabilizar un sistema controlable mediante realimentación de estados. Para ello es suficiente, definir una entrada $u = -Kx$ tal que el sistema en lazo cerrado $\dot x = (A-BK)x$ cumpla que $(A-BK)$ tiene todos sus autovalores en el semiplano complejo negativo. Esto nos da ---en principio--- una gran libertad para elegir la ganancia de realimentacion $K$. Debemos valorar, sin embargo, cual es el comportamiento que deseamos para el sistema realimentado. Si elegimos una ganancia $K$ que coloque los autovalores del sistema muy a la izquierda en el plano complejo, el sistema convergerá muy rápido, pero exigirá un gran esfuerzo de control. Más aún, si pensamos en sistemas reales, tenemos que contar con sus límites físicos para asegurarnos que el sistema puede responder sin llegar a la saturación o, lo que es peor, romperse. En el otro extremo, si situamos los polos muy cerca del eje imaginario, el sistema tardará mucho en estabilizarse e incluso es posible que se desestabilice, debido a las perturbaciones y errores propios de cualquier sistema real.

El Regulador Cuadrático Lineal, \emph{Linear Cuadratic Regulator (LQR)}, ofrece un posible método para ajustar la realimentación de un sistema lineal de acuerdo a unos criterios de optimización. El problema se puede describir de la siguiente manera:

Dado un sistema LTI
\begin{equation*}
\dot{x} = Ax+Bu,\ y=Cx,
\end{equation*}

Encontrar la señal de control $u(t)$ que hace mínimo el siguiente criterio,
\begin{equation}\label{eq:lqr}
J_{LQR} = \int_0^{\infty}y(t)^TQy(t)+u(t)^TRu(t)\ dt,
\end{equation}
donde $Q$ y $R$ son matrices definidas positivas, que actúan como pesos.

Si analizamos la ecuación \ref{eq:lqr}, es fácil ver que se trata de un funcional, que mapea soluciones de nuestro sistema $y(t)$ y sus correspondientes señales de control, en números reales. Además, podemos relacionar el término,
\begin{equation*}
\int_0^{\infty}y(t)^TQy(t)\ dt,
\end{equation*}
con lo que le ha \emph{costado} al sistema llegar al equilibrio y al término,
\begin{equation*}
\int_0^{\infty}u(t)^TRu(t)\ dt,
\end{equation*} 
con el esfuerzo de control. El objetivo de criterio empleado en LQR es tratar de minimizar ambos términos, pero como se trata de objetivos contrapuestos, la solución deberá llevarnos a una solución de equilibrio. Las matrices $Q$ y $R$ permiten equalizar dicho equilibrio: SI  $R$ es mucho más grade que $Q$, la manera más efectiva de hacer $J_{LQR}$ pequeño, es emplear una señal de control pequeña a cambio de obtener una salida larga. Sin, por el contrario hacemos $Q$ mucho mayor que $R$, acortaremos la salida a cambio de hacer más grande la señal de control.

\section{Invariantes de Realimentación (Feedback Invariants)}
\begin{definition}[Invariante de realimentación]
Dado un sistema LTI,
\begin{equation*}
\dot{x} =Ax+Bu,\ x \in \mathbb{R}^n,\ u \in \mathbb{R}^k,\ y \in \mathbb{R}^m,
\end{equation*}
decimos que el funcional,
\begin{equation*}
H\left(x(\cdot),u(\cdot)\right),
\end{equation*}
que depende de la entrada y el estado, es un invariante de realimentación para el sistema si su valor depende solo de la condición inicial del sistema $x(0)$ y no de la señal de entrada específica $u(\cdot)$.
\qed
\end{definition}

\begin{lemma}[Invariante de realimentación]
Para toda matriz P, simetrica, el funcional
\begin{equation*}
H\left(x(\cdot),u(\cdot)\right):=-\int_0^{\infty}\left(Ax(t)+Bu(t)\right)^TPx(t)+x(t)P\left(Ax(t)+Bu(t)\right)dt
\end{equation*}
es un invariante para el sistema $\dot{x} = Ax+Bu$ siempre que $\lim_{t\rightarrow \infty} x(t)= 0$
\qed
\end{lemma}
\begin{proof}
Si reescribimos $H$ como
\begin{equation*}
\begin{split}
H\left(x(\cdot),u(\cdot)\right) &= -\int_0^{\infty}\dot{x}(t)^TPx(t)+x(t)^TP\dot{x}(t)dt\\
&= -\int_0^{\infty}\frac{d\left(x(t)^TPx(t)\right)}{dt}dt\\
&=x(0)^TPx(0) -\lim_{t\rightarrow \infty} x(t)^TPx(t) = x(0)^TPx(0)
\end{split}
\end{equation*}
\end{proof}

Supongamos que podemos escribir un criterio $J$ que deseamos minimizar, mediante una elección adecuada de la señal del control $u(\cdot)$, de la siguiente manera:
\begin{equation}
J = H\left(x(\cdot),u(\cdot)\right) + \int_0^{\infty} \Lambda \left(x(t),u(t)\right)dt,
\end{equation}

donde $H$ es un invariante de realimentación y la función $\Lambda(x,u)$ tiene la propiedad de que
\begin{equation*}
\min_{u \in \mathbb{R}^k} \Lambda(x,u) = 0,\ \forall x \in \mathbb{R}^n
\end{equation*}

Entonces, la señal de control
\begin{equation*}
u(t) = \argmin_{u \in \mathbb{R}^k} \lambda (x,u),
\end{equation*}

